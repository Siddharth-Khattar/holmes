---
phase: 03-file-ingestion
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/models/file.py
  - backend/app/models/__init__.py
  - backend/app/schemas/file.py
  - backend/app/schemas/__init__.py
  - backend/alembic/versions/xxx_add_case_files_table.py
autonomous: true

must_haves:
  truths:
    - "CaseFile model exists with all required fields from CONTEXT.md"
    - "Database migration creates case_files table"
    - "Pydantic schemas exist for API request/response"
  artifacts:
    - path: "backend/app/models/file.py"
      provides: "CaseFile SQLAlchemy model with FileStatus and FileCategory enums"
      contains: "class CaseFile"
    - path: "backend/app/schemas/file.py"
      provides: "FileResponse, FileCreate, FileListResponse schemas"
      contains: "class FileResponse"
    - path: "backend/alembic/versions/*_add_case_files_table.py"
      provides: "Migration for case_files table"
      contains: "op.create_table"
  key_links:
    - from: "backend/app/models/file.py"
      to: "backend/app/models/case.py"
      via: "ForeignKey relationship"
      pattern: "ForeignKey.*cases\\.id"
---

<objective>
Create database model and Pydantic schemas for case files.

Purpose: Establish the data layer foundation that all file upload/management operations depend on. The CaseFile model tracks file metadata, storage location, processing status, and relationships to cases.

Output: SQLAlchemy model, Alembic migration, Pydantic schemas ready for API endpoints.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-file-ingestion/03-CONTEXT.md
@.planning/phases/03-file-ingestion/03-RESEARCH.md
@backend/app/models/case.py
@backend/app/models/base.py
@backend/app/schemas/case.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CaseFile model with enums</name>
  <files>backend/app/models/file.py, backend/app/models/__init__.py</files>
  <action>
Create `backend/app/models/file.py` with:

1. **FileStatus enum** (5 states per CONTEXT.md):
   - UPLOADING, UPLOADED, QUEUED, PROCESSING, ANALYZED, ERROR

2. **FileCategory enum** (auto-detected from MIME type):
   - DOCUMENT, IMAGE, VIDEO, AUDIO

3. **CaseFile model** with fields:
   - `id`: UUID, primary key, server_default gen_random_uuid()
   - `case_id`: UUID, ForeignKey to cases.id with CASCADE delete, indexed
   - `original_filename`: String(255), not null
   - `storage_path`: String(500), not null (GCS path like cases/{case_id}/files/{uuid}.ext)
   - `mime_type`: String(100), not null
   - `size_bytes`: BigInteger, not null
   - `category`: Enum FileCategory, not null
   - `status`: Enum FileStatus, default UPLOADED, not null
   - `content_hash`: String(64), not null (SHA-256 hex)
   - `description`: Text, nullable
   - `error_message`: Text, nullable
   - `page_count`: Integer, nullable (for documents)
   - `duration_seconds`: Integer, nullable (for media)
   - `latitude`: Float, nullable (geolocation for mobile)
   - `longitude`: Float, nullable
   - `created_at`: DateTime with timezone, server_default now()
   - `updated_at`: DateTime with timezone, server_default now(), onupdate now()
   - `case`: relationship to Case

4. Add index on (case_id, content_hash) for duplicate detection

5. Update `backend/app/models/__init__.py` to export CaseFile, FileStatus, FileCategory

Follow the exact patterns from `case.py` for typing, imports, and column definitions. Add ABOUTME comment at top.
  </action>
  <verify>
```bash
cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend
source .venv/bin/activate
python -c "from app.models.file import CaseFile, FileStatus, FileCategory; print('Model imports OK')"
```
  </verify>
  <done>CaseFile model exists with all fields, enums defined, model importable without errors</done>
</task>

<task type="auto">
  <name>Task 2: Create Alembic migration for case_files table</name>
  <files>backend/alembic/versions/*_add_case_files_table.py</files>
  <action>
Create a new Alembic migration:

```bash
cd backend
source .venv/bin/activate
alembic revision -m "add_case_files_table"
```

Edit the generated migration file to:

1. Create `filestatus` enum type with values: UPLOADING, UPLOADED, QUEUED, PROCESSING, ANALYZED, ERROR
2. Create `filecategory` enum type with values: DOCUMENT, IMAGE, VIDEO, AUDIO
3. Create `case_files` table with all columns from CaseFile model
4. Add foreign key constraint to cases.id with ON DELETE CASCADE
5. Create indexes:
   - `idx_case_files_case_id` on case_id
   - `idx_case_files_duplicate_check` on (case_id, content_hash)
6. Add downgrade to drop table and enum types

Reference the existing cases migration for patterns.
  </action>
  <verify>
```bash
cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend
source .venv/bin/activate
# Check migration is valid (doesn't run it, just checks syntax)
alembic check || echo "Alembic check complete"
```
  </verify>
  <done>Migration file exists, creates case_files table with all columns, indexes, and constraints</done>
</task>

<task type="auto">
  <name>Task 3: Create Pydantic schemas for file API</name>
  <files>backend/app/schemas/file.py, backend/app/schemas/__init__.py</files>
  <action>
Create `backend/app/schemas/file.py` with Pydantic models:

1. **FileCreate** (for upload endpoint):
   - `description`: str | None = None
   - `latitude`: float | None = None
   - `longitude`: float | None = None

2. **FileResponse** (API response):
   - `id`: UUID
   - `case_id`: UUID
   - `name`: str (mapped from original_filename)
   - `original_filename`: str
   - `storage_path`: str
   - `mime_type`: str
   - `size_bytes`: int
   - `category`: FileCategory
   - `status`: FileStatus
   - `content_hash`: str
   - `description`: str | None
   - `error_message`: str | None
   - `page_count`: int | None
   - `duration_seconds`: int | None
   - `latitude`: float | None
   - `longitude`: float | None
   - `created_at`: datetime
   - `updated_at`: datetime
   - `duplicate_of`: UUID | None = None (for warning about duplicates)
   - Config: from_attributes = True

3. **FileListResponse** (paginated list):
   - `files`: list[FileResponse]
   - `total`: int
   - `page`: int
   - `per_page`: int

4. **FileStatusUpdate** (for SSE events):
   - `file_id`: UUID
   - `status`: FileStatus
   - `error_message`: str | None = None

5. **DownloadUrlResponse**:
   - `download_url`: str
   - `expires_in`: int (seconds)

Update `backend/app/schemas/__init__.py` to export all new schemas.

Follow patterns from `case.py` for imports and Config.
  </action>
  <verify>
```bash
cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend
source .venv/bin/activate
python -c "from app.schemas.file import FileResponse, FileCreate, FileListResponse, DownloadUrlResponse; print('Schemas import OK')"
```
  </verify>
  <done>All Pydantic schemas defined and importable, following existing patterns</done>
</task>

</tasks>

<verification>
```bash
cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend
source .venv/bin/activate

# Type check the new files
python -m py_compile app/models/file.py
python -m py_compile app/schemas/file.py

# Verify all imports work
python -c "
from app.models.file import CaseFile, FileStatus, FileCategory
from app.schemas.file import FileResponse, FileCreate, FileListResponse, DownloadUrlResponse
print('All imports successful')
"

# Run ruff lint
ruff check app/models/file.py app/schemas/file.py
```
</verification>

<success_criteria>
- CaseFile model defines all fields from CONTEXT.md
- FileStatus enum has 6 states (UPLOADING, UPLOADED, QUEUED, PROCESSING, ANALYZED, ERROR)
- FileCategory enum has 4 types (DOCUMENT, IMAGE, VIDEO, AUDIO)
- Migration creates case_files table with proper constraints
- Pydantic schemas ready for API use
- All files pass type checking and linting
</success_criteria>

<output>
After completion, create `.planning/phases/03-file-ingestion/03-01-SUMMARY.md`
</output>
