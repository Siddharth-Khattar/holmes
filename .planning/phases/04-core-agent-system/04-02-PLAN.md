---
phase: 04-core-agent-system
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - backend/app/models/agent_execution.py
  - backend/app/models/__init__.py
  - backend/app/schemas/agent.py
  - backend/app/schemas/__init__.py
  - backend/alembic/versions/YYYYMMDD_agent_execution.py
autonomous: true

must_haves:
  truths:
    - "Agent executions are logged to database with full audit trail"
    - "Triage output schema captures domain scores, entities, summaries, and complexity"
    - "Database migration creates agent_executions table"
  artifacts:
    - path: "backend/app/models/agent_execution.py"
      provides: "SQLAlchemy model for agent execution logging"
      exports: ["AgentExecution", "AgentExecutionStatus"]
    - path: "backend/app/schemas/agent.py"
      provides: "Pydantic schemas for agent inputs/outputs"
      exports: ["TriageOutput", "DomainScore", "ExtractedEntity", "AgentExecutionCreate"]
  key_links:
    - from: "backend/app/models/agent_execution.py"
      to: "backend/app/models/case.py"
      via: "Foreign key to cases table"
      pattern: "ForeignKey.*cases\\.id"
    - from: "backend/app/schemas/agent.py"
      to: "backend/app/models/agent_execution.py"
      via: "Schema validates model data"
      pattern: "class.*Output|class.*Create"
---

<objective>
Create database models and Pydantic schemas for agent execution logging and triage output.

Purpose: Enable full audit trail of agent executions including inputs, outputs, timing, and token usage. Define structured output schemas for Triage Agent results.

Output: SQLAlchemy models and Pydantic schemas ready for agent execution tracking, plus migration to create database tables.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-core-agent-system/04-CONTEXT.md
@.planning/phases/04-core-agent-system/04-RESEARCH.md

# Existing patterns
@backend/app/models/file.py
@backend/app/models/case.py
@backend/app/schemas/file.py
@backend/app/schemas/case.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create agent execution SQLAlchemy model</name>
  <files>
    - backend/app/models/agent_execution.py
    - backend/app/models/__init__.py
  </files>
  <action>
Create backend/app/models/agent_execution.py with:

1. **AgentExecutionStatus enum**:
   - PENDING, RUNNING, COMPLETED, FAILED, RETRYING

2. **AgentExecution model** with fields per CONTEXT.md "full execution log" requirement:
   - `id: UUID` - primary key (gen_random_uuid)
   - `case_id: UUID` - FK to cases.id (CASCADE delete)
   - `workflow_id: UUID` - Groups executions in same analysis run
   - `agent_name: str` - e.g., "triage", "orchestrator" (String 100)
   - `agent_type: str` - e.g., "LlmAgent", "ParallelAgent" (String 50)
   - `model_name: str` - e.g., "gemini-3-flash-preview" (String 100)
   - `status: AgentExecutionStatus` - enum
   - `parent_execution_id: UUID | None` - FK to self for sub-agent tracking
   - `input_data: dict` - JSONB, agent input context
   - `output_data: dict | None` - JSONB, agent output
   - `thinking_traces: list | None` - JSONB array, captured thinking
   - `tools_called: list | None` - JSONB array, tool invocations
   - `error_message: str | None` - Text, if failed
   - `input_tokens: int | None` - Token count
   - `output_tokens: int | None` - Token count
   - `started_at: datetime` - Timestamp with timezone
   - `completed_at: datetime | None` - Timestamp with timezone
   - `created_at: datetime` - server_default now()
   - `updated_at: datetime` - server_default now(), onupdate now()

3. **Indexes**:
   - `idx_agent_executions_case_id` on case_id
   - `idx_agent_executions_workflow_id` on workflow_id
   - `idx_agent_executions_parent` on parent_execution_id

4. **Relationship** to Case model (add back_populates if Case needs it)

Update backend/app/models/__init__.py to export AgentExecution and AgentExecutionStatus.

Add 2-line ABOUTME comment.
  </action>
  <verify>
Run `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend && python -c "from app.models.agent_execution import AgentExecution, AgentExecutionStatus; print('AgentExecution model importable')"` to verify import.
  </verify>
  <done>AgentExecution model created with full audit trail fields, JSONB columns for flexible data, and proper indexes.</done>
</task>

<task type="auto">
  <name>Task 2: Create Pydantic schemas for agent data</name>
  <files>
    - backend/app/schemas/agent.py
    - backend/app/schemas/__init__.py
  </files>
  <action>
Create backend/app/schemas/agent.py with:

1. **DomainScore** - Per CONTEXT.md "confidence percentages":
   ```python
   class DomainScore(BaseModel):
       domain: Literal["financial", "legal", "strategy", "evidence"]
       score: float = Field(ge=0, le=100, description="Confidence 0-100")
       reasoning: str | None = None
   ```

2. **ExtractedEntity** - Per CONTEXT.md "quick entities":
   ```python
   class ExtractedEntity(BaseModel):
       type: Literal["person", "organization", "date", "location", "amount", "legal_term"]
       value: str
       context: str | None = None  # Surrounding text
       confidence: float = Field(ge=0, le=1, default=1.0)
   ```

3. **FileSummary** - Per CONTEXT.md "short and detailed summaries":
   ```python
   class FileSummary(BaseModel):
       short: str = Field(max_length=200, description="1-2 sentence summary")
       detailed: str = Field(max_length=2000, description="Paragraph summary")
   ```

4. **ComplexityAssessment** - Per CONTEXT.md "hybrid approach":
   ```python
   class ComplexityAssessment(BaseModel):
       tier: Literal["low", "medium", "high"]
       token_estimate: int | None = None  # From ADK metadata when available
       reasoning: str | None = None
   ```

5. **FileGrouping** - Per CONTEXT.md "suggest groupings":
   ```python
   class FileGrouping(BaseModel):
       group_name: str
       file_ids: list[str]
       reason: str
   ```

6. **TriageFileResult** - Per-file triage output:
   ```python
   class TriageFileResult(BaseModel):
       file_id: str
       domain_scores: list[DomainScore]
       entities: list[ExtractedEntity]
       summary: FileSummary
       complexity: ComplexityAssessment
       confidence: float = Field(ge=0, le=1, description="Overall extraction confidence")
       is_corrupted: bool = False
       corruption_notes: str | None = None
   ```

7. **TriageOutput** - Complete triage agent output:
   ```python
   class TriageOutput(BaseModel):
       file_results: list[TriageFileResult]
       suggested_groupings: list[FileGrouping]
       total_token_estimate: int | None = None
   ```

8. **AgentExecutionCreate** - For creating execution records:
   ```python
   class AgentExecutionCreate(BaseModel):
       case_id: UUID
       workflow_id: UUID
       agent_name: str
       agent_type: str
       model_name: str
       input_data: dict
       parent_execution_id: UUID | None = None
   ```

9. **AgentExecutionUpdate** - For updating execution records:
   ```python
   class AgentExecutionUpdate(BaseModel):
       status: AgentExecutionStatus | None = None
       output_data: dict | None = None
       thinking_traces: list | None = None
       tools_called: list | None = None
       error_message: str | None = None
       input_tokens: int | None = None
       output_tokens: int | None = None
       completed_at: datetime | None = None
   ```

10. **AgentExecutionResponse** - API response:
    ```python
    class AgentExecutionResponse(BaseModel):
        id: UUID
        case_id: UUID
        workflow_id: UUID
        agent_name: str
        status: AgentExecutionStatus
        # ... other fields
        model_config = ConfigDict(from_attributes=True)
    ```

Update backend/app/schemas/__init__.py to export new schemas.

Add 2-line ABOUTME comment.
  </action>
  <verify>
Run `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend && python -c "from app.schemas.agent import TriageOutput, DomainScore; print('Agent schemas importable')"` to verify imports.
Run `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend && python -c "from app.schemas.agent import DomainScore; d = DomainScore(domain='financial', score=85.5); print(f'DomainScore validates: {d}')"` to verify validation.
  </verify>
  <done>Pydantic schemas created for all triage output types and agent execution records.</done>
</task>

<task type="auto">
  <name>Task 3: Create database migration for agent_executions table</name>
  <files>
    - backend/alembic/versions/YYYYMMDD_agent_execution.py
  </files>
  <action>
Create Alembic migration for agent_executions table.

Run: `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend && alembic revision --autogenerate -m "add_agent_executions_table"`

Review the generated migration to ensure:
1. Creates `agentexecutionstatus` enum type
2. Creates `agent_executions` table with all columns
3. Creates indexes: idx_agent_executions_case_id, idx_agent_executions_workflow_id, idx_agent_executions_parent
4. FK constraint to cases.id with CASCADE delete
5. Self-referential FK for parent_execution_id with SET NULL on delete

If autogenerate doesn't capture JSONB properly, manually specify:
```python
sa.Column('input_data', postgresql.JSONB(), nullable=False),
sa.Column('output_data', postgresql.JSONB(), nullable=True),
sa.Column('thinking_traces', postgresql.JSONB(), nullable=True),
sa.Column('tools_called', postgresql.JSONB(), nullable=True),
```

The migration filename will be auto-generated with timestamp prefix.
  </action>
  <verify>
Run `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend && alembic check` to verify migration is valid.
Run `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend && alembic heads` to verify migration chain is intact.
  </verify>
  <done>Database migration created for agent_executions table with all columns, indexes, and constraints.</done>
</task>

</tasks>

<verification>
1. All new files have ABOUTME comments
2. AgentExecution model imports cleanly
3. All Pydantic schemas validate correctly
4. Migration passes alembic check
5. No type errors: `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend && ruff check app/`
6. JSONB columns properly defined for flexible data storage
</verification>

<success_criteria>
- AgentExecution model captures full audit trail per CONTEXT.md
- TriageOutput schema matches CONTEXT.md decisions (domain scores, entities, summaries, complexity, groupings)
- Database migration ready to apply
- Schemas exported from app.schemas and app.models
- All fields have appropriate types (no `Any`)
</success_criteria>

<output>
After completion, create `.planning/phases/04-core-agent-system/04-02-SUMMARY.md`
</output>
