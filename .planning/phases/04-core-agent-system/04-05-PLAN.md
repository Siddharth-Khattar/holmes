---
phase: 04-core-agent-system
plan: 05
type: execute
wave: 3
depends_on: ["04-02", "04-03"]
files_modified:
  - backend/app/api/agents.py
  - backend/app/api/sse.py
  - backend/app/services/agent_events.py
  - backend/app/main.py
autonomous: true

must_haves:
  truths:
    - "SSE events fire for agent lifecycle (AGENT_SPAWNED, THINKING_UPDATE, AGENT_COMPLETED)"
    - "API endpoint starts analysis workflow for case files"
    - "Agent execution is logged and SSE events are published"
    - "Frontend receives real-time agent status updates"
  artifacts:
    - path: "backend/app/api/agents.py"
      provides: "Agent execution API endpoints"
      exports: ["router"]
    - path: "backend/app/services/agent_events.py"
      provides: "Agent event publishing for SSE"
      exports: ["publish_agent_event", "AgentEventType"]
    - path: "backend/app/api/sse.py"
      provides: "Command center SSE stream"
      exports: ["router"]
  key_links:
    - from: "backend/app/api/agents.py"
      to: "backend/app/agents/triage.py"
      via: "Invokes run_triage"
      pattern: "run_triage"
    - from: "backend/app/api/agents.py"
      to: "backend/app/agents/orchestrator.py"
      via: "Invokes run_orchestrator"
      pattern: "run_orchestrator"
    - from: "backend/app/services/agent_events.py"
      to: "backend/app/api/sse.py"
      via: "Publishes to SSE subscribers"
      pattern: "publish_agent_event.*_agent_subscribers"
---

<objective>
Create API endpoints for starting analysis and SSE streaming for agent lifecycle events.

Purpose: Connect the agent infrastructure to the frontend. Enable starting analysis workflows via API and receiving real-time updates via SSE. This completes the Phase 4 backend integration.

Output: Working API endpoint to start case analysis and SSE stream that delivers agent events to the Command Center UI.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-core-agent-system/04-CONTEXT.md
@.planning/phases/04-core-agent-system/04-RESEARCH.md
@.planning/phases/04-core-agent-system/04-01-SUMMARY.md
@.planning/phases/04-core-agent-system/04-02-SUMMARY.md
@.planning/phases/04-core-agent-system/04-03-SUMMARY.md

# Existing SSE patterns
@backend/app/api/sse.py
@backend/app/api/files.py

# Frontend types to match
@frontend/src/types/command-center.ts
@frontend/src/hooks/useCommandCenterSSE.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create agent event publishing service</name>
  <files>
    - backend/app/services/agent_events.py
    - backend/app/services/__init__.py
  </files>
  <action>
Create backend/app/services/agent_events.py with:

1. **AgentEventType enum** matching frontend expectations (command-center.ts):
   ```python
   class AgentEventType(str, Enum):
       AGENT_STARTED = "agent-started"
       AGENT_COMPLETE = "agent-complete"
       AGENT_ERROR = "agent-error"
       THINKING_UPDATE = "thinking-update"
       TOOL_CALLED = "tool-called"
       PROCESSING_COMPLETE = "processing-complete"
   ```

2. **Event data classes** matching frontend CommandCenterSSEEvent:
   ```python
   @dataclass
   class AgentStartedEventData:
       type: Literal["agent-started"] = "agent-started"
       agentType: str  # triage, orchestrator, etc.
       taskId: str
       fileId: str
       fileName: str

   @dataclass
   class AgentCompleteEventData:
       type: Literal["agent-complete"] = "agent-complete"
       agentType: str
       taskId: str
       result: dict  # AgentResult structure

   @dataclass
   class AgentErrorEventData:
       type: Literal["agent-error"] = "agent-error"
       agentType: str
       taskId: str
       error: str

   @dataclass
   class ProcessingCompleteEventData:
       type: Literal["processing-complete"] = "processing-complete"
       caseId: str
       filesProcessed: int
       entitiesCreated: int
       relationshipsCreated: int
   ```

3. **Subscriber management** (similar to file events):
   ```python
   _agent_subscribers: dict[str, list[asyncio.Queue]] = defaultdict(list)

   def subscribe_to_agent_events(case_id: str) -> asyncio.Queue:
       """Subscribe to agent events for a case."""
       queue = asyncio.Queue(maxsize=100)
       _agent_subscribers[case_id].append(queue)
       return queue

   def unsubscribe_from_agent_events(case_id: str, queue: asyncio.Queue):
       """Unsubscribe from agent events."""
       try:
           _agent_subscribers[case_id].remove(queue)
       except ValueError:
           pass
   ```

4. **Publish function**:
   ```python
   async def publish_agent_event(
       case_id: str,
       event_type: AgentEventType,
       data: dict
   ) -> None:
       """Publish agent event to all subscribers for a case."""
       event = {"event": event_type.value, "data": json.dumps(data)}
       for queue in _agent_subscribers.get(case_id, []):
           try:
               queue.put_nowait(event)
           except asyncio.QueueFull:
               pass  # Skip slow consumers
   ```

5. **Convenience functions** for common events:
   ```python
   async def emit_agent_started(case_id: str, agent_type: str, task_id: str, file_id: str, file_name: str):
       ...

   async def emit_agent_complete(case_id: str, agent_type: str, task_id: str, result: dict):
       ...

   async def emit_agent_error(case_id: str, agent_type: str, task_id: str, error: str):
       ...
   ```

Update backend/app/services/__init__.py to export the new module.

Add 2-line ABOUTME comment.
  </action>
  <verify>
Run `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend && python -c "from app.services.agent_events import AgentEventType, publish_agent_event; print('Agent events service importable')"` to verify imports.
  </verify>
  <done>Agent event publishing service created with subscriber management and event emission functions.</done>
</task>

<task type="auto">
  <name>Task 2: Add command center SSE endpoint</name>
  <files>
    - backend/app/api/sse.py
  </files>
  <action>
Update backend/app/api/sse.py to add command center stream:

1. **Import agent events service**:
   ```python
   from app.services.agent_events import (
       subscribe_to_agent_events,
       unsubscribe_from_agent_events,
   )
   ```

2. **Command center event generator** (pattern matches file_status_generator):
   ```python
   async def command_center_generator(case_id: str):
       """
       Generate agent lifecycle events for Command Center visualization.

       Events:
       - agent-started: Agent begins processing
       - agent-complete: Agent finishes with results
       - agent-error: Agent encountered an error
       - thinking-update: Agent reasoning trace (batched)
       - tool-called: Agent invoked a tool
       - processing-complete: All agents finished

       Heartbeat every 15 seconds per REQ-INF-004.
       """
       queue = subscribe_to_agent_events(case_id)

       try:
           while True:
               try:
                   event = await asyncio.wait_for(queue.get(), timeout=15.0)
                   yield event
               except TimeoutError:
                   yield {"event": "heartbeat", "data": "ping"}
       finally:
           unsubscribe_from_agent_events(case_id, queue)
   ```

3. **SSE endpoint** matching frontend expectation (/api/cases/:caseId/command-center/stream):
   ```python
   @router.get("/sse/cases/{case_id}/command-center/stream")
   async def command_center_stream(case_id: str):
       """
       SSE endpoint for Command Center agent visualization.

       Streams agent lifecycle events:
       - agent-started: When an agent begins processing
       - agent-complete: When an agent finishes with results
       - agent-error: When an agent encounters an error
       - processing-complete: When all processing is done

       Heartbeat every 15 seconds to keep connection alive.
       """
       return EventSourceResponse(
           command_center_generator(case_id),
           headers={
               "X-Accel-Buffering": "no",
               "Cache-Control": "no-cache, no-transform",
           },
       )
   ```

Note: Frontend expects `/api/cases/${caseId}/command-center/stream` but we use `/sse/` prefix. Frontend will need API proxy or we add both routes. For now, add the /sse/ route. Frontend can be updated or proxy configured.
  </action>
  <verify>
Run `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend && python -c "from app.api.sse import command_center_stream; print('Command center SSE endpoint defined')"` to verify endpoint is defined.
  </verify>
  <done>Command center SSE endpoint added with heartbeat and proper headers for Cloud Run.</done>
</task>

<task type="auto">
  <name>Task 3: Create agent execution API endpoints</name>
  <files>
    - backend/app/api/agents.py
    - backend/app/main.py
  </files>
  <action>
Create backend/app/api/agents.py with:

1. **Start analysis endpoint**:
   ```python
   @router.post("/api/cases/{case_id}/analyze")
   async def start_analysis(
       case_id: UUID,
       background_tasks: BackgroundTasks,
       session: AsyncSession = Depends(get_db),
       current_user: User = Depends(get_current_user),
   ) -> AnalysisStartResponse:
       """
       Start agent analysis for all uploaded files in a case.

       Per CONTEXT.md: "Batch after uploads - user explicitly starts analysis"

       This triggers:
       1. Triage Agent on all UPLOADED files
       2. Orchestrator Agent with triage results
       3. (Future) Domain agents based on routing

       Returns workflow_id for tracking.
       """
   ```

2. **Analysis start response schema**:
   ```python
   class AnalysisStartResponse(BaseModel):
       workflow_id: UUID
       case_id: UUID
       files_queued: int
       message: str
   ```

3. **Background analysis task** (stage-isolated pipeline controller):
   ```python
   async def run_analysis_workflow(
       case_id: str,
       workflow_id: str,
       user_id: str,
       file_ids: list[str],
   ):
       """
       Background task that orchestrates the stage-isolated analysis pipeline.

       Each stage gets a FRESH ADK session to prevent context window bloat
       from multimodal file content. Inter-stage data flows via database.

       Steps:
       1. Update file statuses to QUEUED
       2. Stage 1: Run Triage Agent (fresh session, multimodal files)
           → Store TriageOutput in agent_executions table
       3. Stage 2: Run Orchestrator Agent (fresh session, text-only input)
           → Store RoutingDecisions in agent_executions table
       4. (Future) Stage 3: Run Domain Agents (parallel fresh sessions)
       5. (Future) Stage 4: Run Synthesis Agent (fresh session)
       6. Update file statuses to ANALYZED
       7. Emit processing-complete event

       SSE events emitted at each stage transition:
       - STAGE_STARTED: When a pipeline stage begins
       - AGENT_SPAWNED: When an agent within a stage starts
       - AGENT_COMPLETED: When an agent finishes
       - STAGE_COMPLETED: When a pipeline stage finishes
       - PROCESSING_COMPLETE: When entire pipeline is done
       """
   ```

4. **Get analysis status endpoint**:
   ```python
   @router.get("/api/cases/{case_id}/analysis/{workflow_id}")
   async def get_analysis_status(
       case_id: UUID,
       workflow_id: UUID,
       session: AsyncSession = Depends(get_db),
   ) -> AnalysisStatusResponse:
       """Get current status of an analysis workflow."""
   ```

5. **Analysis status response**:
   ```python
   class AnalysisStatusResponse(BaseModel):
       workflow_id: UUID
       case_id: UUID
       status: Literal["pending", "triage", "orchestrating", "domain_analysis", "complete", "error"]
       triage_result: TriageOutput | None
       orchestrator_result: OrchestratorOutput | None
       started_at: datetime
       completed_at: datetime | None
       error: str | None
   ```

Update backend/app/main.py:
- Import agents router
- Include router: `app.include_router(agents.router, tags=["agents"])`

Add 2-line ABOUTME comment.
  </action>
  <verify>
Run `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend && python -c "from app.api.agents import router; print('Agents API router defined')"` to verify router.
Run `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend && python -c "from app.main import app; routes = [r.path for r in app.routes]; print('analyze' in str(routes))"` to verify route is included.
  </verify>
  <done>Agent execution API created with start analysis, status endpoints, and background task integration.</done>
</task>

</tasks>

<verification>
1. All new files have ABOUTME comments
2. SSE events match frontend types (command-center.ts)
3. Analysis workflow runs in background
4. Events published at each stage
5. File statuses updated through pipeline
6. Auth middleware protects endpoints
7. `ruff check app/` passes
8. API documentation shows new endpoints (run backend, check /docs)
</verification>

<success_criteria>
- POST /api/cases/{case_id}/analyze starts workflow
- SSE /sse/cases/{case_id}/command-center/stream delivers events
- agent-started, agent-complete, agent-error events fire correctly
- processing-complete event fires when workflow done
- File statuses transition: UPLOADED -> QUEUED -> PROCESSING -> ANALYZED
- Workflow can be tracked via status endpoint
</success_criteria>

<output>
After completion, create `.planning/phases/04-core-agent-system/04-05-SUMMARY.md`
</output>
