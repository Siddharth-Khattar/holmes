---
phase: 06-domain-agents
plan: 03
type: execute
wave: 2
depends_on: ["06-01", "06-02"]
files_modified:
  - backend/app/agents/financial.py
  - backend/app/agents/legal.py
  - backend/app/agents/evidence.py
  - backend/app/agents/domain_runner.py
autonomous: true

must_haves:
  truths:
    - "Financial, Legal, and Evidence agents process files and produce structured output"
    - "Agents execute in parallel via asyncio.gather with independent database sessions"
    - "Each agent creates a stage-isolated ADK session (no shared context)"
    - "Pro-to-Flash fallback works transparently with SSE fallback warning"
    - "Agent execution records logged to database with parent tracking"
    - "Partial results preserved when one agent fails"
  artifacts:
    - path: "backend/app/agents/financial.py"
      provides: "FinancialAgent class + run_financial function"
      contains: "async def run_financial"
    - path: "backend/app/agents/legal.py"
      provides: "LegalAgent class + run_legal function"
      contains: "async def run_legal"
    - path: "backend/app/agents/evidence.py"
      provides: "EvidenceAgent class + run_evidence function"
      contains: "async def run_evidence"
    - path: "backend/app/agents/domain_runner.py"
      provides: "run_domain_agents_parallel function for asyncio.gather orchestration"
      contains: "async def run_domain_agents_parallel"
  key_links:
    - from: "backend/app/agents/domain_runner.py"
      to: "backend/app/agents/financial.py"
      via: "import and call run_financial"
      pattern: "from app.agents.financial import run_financial"
    - from: "backend/app/agents/domain_runner.py"
      to: "backend/app/schemas/agent.py"
      via: "import OrchestratorOutput for routing decisions"
      pattern: "from app.schemas.agent import OrchestratorOutput"
    - from: "backend/app/agents/financial.py"
      to: "backend/app/services/adk_service.py"
      via: "uses build_domain_agent_content, create_stage_runner, get_or_create_stage_session"
      pattern: "from app.services.adk_service import"
---

<objective>
Implement the three parallel domain agents (Financial, Legal, Evidence) and the parallel execution orchestrator. Each agent follows the exact same pattern as `run_triage`/`run_orchestrator` with stage-isolated sessions, Pro-to-Flash fallback, and execution logging.

Purpose: These are the core analysis agents that extract domain-specific findings from case files. They run concurrently after the Orchestrator routes files. The parallel runner uses asyncio.gather with independent database sessions to avoid race conditions.

Output: 3 domain agent modules (financial.py, legal.py, evidence.py) + 1 parallel runner module (domain_runner.py).
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-domain-agents/06-CONTEXT.md
@.planning/phases/06-domain-agents/06-RESEARCH.md

@backend/app/agents/triage.py
@backend/app/agents/orchestrator.py
@backend/app/agents/parsing.py
@backend/app/agents/factory.py
@backend/app/agents/base.py
@backend/app/schemas/agent.py
@backend/app/services/adk_service.py
@backend/app/services/agent_events.py
@backend/app/models/agent_execution.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Financial, Legal, and Evidence agent modules</name>
  <files>
    backend/app/agents/financial.py
    backend/app/agents/legal.py
    backend/app/agents/evidence.py
  </files>
  <action>
Create three agent modules following the EXACT pattern from `triage.py` and `orchestrator.py`. All three follow the same structure -- the only differences are: agent name, factory method, output schema, model constants, and prompt content.

**For each agent module (financial.py, legal.py, evidence.py):**

1. **ABOUTME header**: 2-line comment explaining the file.

2. **Imports**: Same as triage.py -- json, logging, datetime, UUID, Event, types, AsyncSession, PublishFn, AgentFactory, parsing helpers, get_settings, AgentExecution, AgentExecutionStatus, CaseFile, the domain output schema, adk_service functions. Additionally import `build_domain_agent_content` from adk_service (NOT `build_agent_content`).

3. **Agent wrapper class** (e.g., `FinancialAgent`):
   - `__init__(self, case_id, model, publish_fn)` -- model parameter defaults to MODEL_PRO but accepts MODEL_FLASH for fallback
   - Creates agent via `AgentFactory.create_financial_agent(case_id, model=model, publish_fn=publish_fn)`
   - Has `agent` property

4. **Output parsing function** (e.g., `parse_financial_output`):
   - Same reverse-event-scan pattern as `parse_triage_output`
   - Uses `extract_json_from_text` from parsing.py
   - Returns `FinancialOutput | None`

5. **Content preparation function** (e.g., `_prepare_financial_content`):
   - Uses `build_domain_agent_content` (NOT `build_agent_content`) to force video/audio through File API
   - Prompt text: "Analyze the following documents for financial insights:" (customize per domain)
   - For Financial: "Analyze the following documents for financial insights. Extract transactions, amounts, anomalies, and account relationships."
   - For Legal: "Analyze the following documents for legal significance. Extract obligations, risks, compliance issues, and legal entities."
   - For Evidence: "Analyze the following documents as physical/digital evidence. Assess authenticity, chain of custody, and corroboration."

6. **Main execution function** (e.g., `run_financial`):
   Signature:
   ```python
   async def run_financial(
       case_id: str,
       workflow_id: str,
       user_id: str,
       files: list[CaseFile],
       hypotheses: list[dict[str, object]],
       db_session: AsyncSession,
       publish_event: PublishFn | None = None,
       parent_execution_id: UUID | None = None,
   ) -> FinancialOutput | None:
   ```

   Implementation follows `run_triage` exactly but with Pro-to-Flash fallback:

   a. Create execution record (PENDING) with `agent_name="financial"`, `model_name=settings.gemini_pro_model`
   b. Mark RUNNING with started_at
   c. Build multimodal content with `build_domain_agent_content`. If hypotheses are non-empty, append a hypothesis context section to the prompt text: `\n\n--- EXISTING HYPOTHESES TO EVALUATE ---\n{json.dumps(hypotheses, indent=2)}`
   d. **Attempt 1 (Pro model):** Create agent with MODEL_PRO, create runner, create stage session (stage="financial"), run, parse output. Use MAX_PARSE_RETRIES = 1 (same as triage).
   e. **If Pro fails (parse failure after retries OR exception):** Attempt 2 with MODEL_FLASH as fallback. Create new agent with model=MODEL_FLASH, new runner, new stage session (stage="financial_fallback"). Log warning. Set a `_fallback_used` flag.
   f. If fallback was used, emit a fallback warning SSE event via `publish_event` if available:
      ```python
      if publish_event and fallback_used:
          _fire_fallback = publish_event(
              "AGENT_FALLBACK",
              {"case_id": case_id, "agent_name": "financial", "fallback_model": MODEL_FLASH},
          )
          if _fire_fallback is not None:
              asyncio.ensure_future(_fire_fallback)
      ```
   g. Update execution record with status, output_data, tokens, thinking_traces, completed_at. If fallback was used, add `"fallback_used": True, "fallback_model": MODEL_FLASH` to execution's output_data metadata.
   h. Return output or None.

   **IMPORTANT differences from triage:**
   - `hypotheses` parameter (list[dict]) for hypothesis evaluation context
   - Pro-to-Flash fallback (triage only uses Flash, no fallback needed)
   - Uses `build_domain_agent_content` instead of `build_agent_content`
   - `parent_execution_id` links to orchestrator execution for audit chain

   The legal.py and evidence.py files follow the IDENTICAL pattern with:
   - legal.py: agent_name="legal", LegalAgent, LegalOutput, parse_legal_output, run_legal, stage="legal"
   - evidence.py: agent_name="evidence", EvidenceAgent, EvidenceOutput, parse_evidence_output, run_evidence, stage="evidence"
  </action>
  <verify>
Run from the backend directory:
1. `python -c "from app.agents.financial import run_financial, FinancialAgent, parse_financial_output; print('Financial agent module OK')"` -- imports work.
2. `python -c "from app.agents.legal import run_legal, LegalAgent, parse_legal_output; print('Legal agent module OK')"` -- imports work.
3. `python -c "from app.agents.evidence import run_evidence, EvidenceAgent, parse_evidence_output; print('Evidence agent module OK')"` -- imports work.
4. `python -c "import inspect; from app.agents.financial import run_financial; sig = inspect.signature(run_financial); assert 'hypotheses' in sig.parameters; print('hypotheses param exists')"` -- verify signature.
  </verify>
  <done>
Three domain agent modules created (financial.py, legal.py, evidence.py), each with: Agent wrapper class, output parser, content preparer using build_domain_agent_content, and run function with Pro-to-Flash fallback, hypothesis context injection, stage-isolated sessions, and execution logging.
  </done>
</task>

<task type="auto">
  <name>Task 2: Parallel execution orchestrator (domain_runner.py)</name>
  <files>backend/app/agents/domain_runner.py</files>
  <action>
Create `backend/app/agents/domain_runner.py` -- the parallel execution coordinator for Financial, Legal, and Evidence agents.

**ABOUTME header**: "Parallel domain agent execution orchestrator using asyncio.gather." / "Routes files to domain agents based on orchestrator decisions and aggregates results."

**Key function: `run_domain_agents_parallel`**

```python
async def run_domain_agents_parallel(
    case_id: str,
    workflow_id: str,
    user_id: str,
    routing: OrchestratorOutput,
    files: list[CaseFile],
    hypotheses: list[dict[str, object]],
    db_session_factory: Callable[..., AsyncContextManager[AsyncSession]],
    publish_event: PublishFn | None = None,
    orchestrator_execution_id: UUID | None = None,
) -> dict[str, BaseModel | None]:
```

**Implementation:**

1. **Build file-to-agent mapping** from `routing.routing_decisions`:
   ```python
   agent_files: dict[str, list[CaseFile]] = {
       "financial": [], "legal": [], "evidence": []
   }
   file_lookup = {str(f.id): f for f in files}

   for decision in routing.routing_decisions:
       for agent_name in decision.target_agents:
           if agent_name in agent_files:
               file = file_lookup.get(decision.file_id)
               if file:
                   agent_files[agent_name].append(file)
   ```

2. **Create async wrapper for each agent** that manages its own database session:
   Each parallel agent MUST create its own database session from the session factory (per RESEARCH.md Pitfall 3). Do NOT share the caller's session.

   ```python
   async def _run_agent_with_session(
       agent_name: str,
       run_fn: Callable,
       agent_files: list[CaseFile],
   ) -> tuple[str, BaseModel | None]:
       async with db_session_factory() as db:
           result = await run_fn(
               case_id=case_id,
               workflow_id=workflow_id,
               user_id=user_id,
               files=agent_files,
               hypotheses=hypotheses,
               db_session=db,
               publish_event=publish_event,
               parent_execution_id=orchestrator_execution_id,
           )
           await db.commit()
           return agent_name, result
   ```

3. **Launch parallel tasks** (only for agents that have files routed to them):
   ```python
   tasks: list[Coroutine] = []
   if agent_files["financial"]:
       tasks.append(_run_agent_with_session("financial", run_financial, agent_files["financial"]))
   if agent_files["legal"]:
       tasks.append(_run_agent_with_session("legal", run_legal, agent_files["legal"]))
   if agent_files["evidence"]:
       tasks.append(_run_agent_with_session("evidence", run_evidence, agent_files["evidence"]))
   ```

4. **Execute concurrently, continue on partial failure:**
   ```python
   results = await asyncio.gather(*tasks, return_exceptions=True)
   ```

5. **Map results back, log failures:**
   ```python
   output: dict[str, BaseModel | None] = {}
   for item in results:
       if isinstance(item, Exception):
           logger.error("Domain agent failed: %s", item)
           continue
       agent_name, result = item
       output[agent_name] = result
   return output
   ```

6. **Log summary** of what ran, what succeeded, what failed.

**Also add a helper function: `build_strategy_context`**

```python
def build_strategy_context(
    domain_results: dict[str, BaseModel | None],
) -> str:
    """Build text summaries of domain agent findings for the Strategy agent.

    Strategy agent receives TEXT summaries (not raw files) from other
    domain agents, per CONTEXT.md decision and RESEARCH.md Pitfall 4.
    """
```

This function iterates over domain_results and for each non-None result:
- Extracts the agent name and finding count
- For each finding: category, title, confidence, and first sentence of description
- Produces a structured text summary like:
  ```
  --- Financial Agent Findings (5 findings) ---
  [Transactions] Invoice Discrepancy (confidence: 78): Invoice amounts for Acme Corp...
  [Anomalies] Round-Tripping Pattern (confidence: 62): Funds appear to cycle through...
  ...
  ```

This summary is what gets injected into the Strategy agent's context (Plan 04 consumes this).

**Type imports needed:** Use `from collections.abc import Callable` and appropriate typing for the session factory. The session factory type should be `Callable[[], AsyncContextManager[AsyncSession]]` -- or use a simpler approach with `Callable` and document the expected signature.
  </action>
  <verify>
Run from the backend directory:
1. `python -c "from app.agents.domain_runner import run_domain_agents_parallel, build_strategy_context; print('domain_runner imports OK')"` -- imports work.
2. `python -c "import inspect; from app.agents.domain_runner import run_domain_agents_parallel; sig = inspect.signature(run_domain_agents_parallel); assert 'db_session_factory' in sig.parameters; print('session factory param exists')"` -- verify session factory parameter.
3. `python -c "from app.agents.domain_runner import build_strategy_context; result = build_strategy_context({}); print(f'Empty context: {repr(result)}')"` -- works with empty input.
  </verify>
  <done>
domain_runner.py created with:
- `run_domain_agents_parallel`: Routes files per orchestrator decisions, runs Financial/Legal/Evidence concurrently via asyncio.gather, each with independent DB session, returns dict of results with partial failure tolerance.
- `build_strategy_context`: Converts domain agent outputs to text summaries for Strategy agent consumption.
  </done>
</task>

</tasks>

<verification>
- All 3 domain agent modules follow the same pattern as triage.py
- Each has: Agent class, output parser, content preparer, run function with Pro-to-Flash fallback
- domain_runner.py orchestrates parallel execution with independent DB sessions
- Hypothesis context injected into agent prompts when available
- Fallback usage tracked in execution records and SSE events
- build_strategy_context produces text summaries for downstream Strategy agent
</verification>

<success_criteria>
- `run_financial`, `run_legal`, `run_evidence` all importable and have correct signatures
- `run_domain_agents_parallel` routes files based on OrchestratorOutput routing_decisions
- Parallel execution uses asyncio.gather with return_exceptions=True
- Each parallel agent creates its own DB session (no shared session)
- Pro-to-Flash fallback implemented in each run function
- `build_strategy_context` converts domain outputs to readable text summaries
- All execution records track parent_execution_id for audit chain
</success_criteria>

<output>
After completion, create `.planning/phases/06-domain-agents/06-03-SUMMARY.md`
</output>
