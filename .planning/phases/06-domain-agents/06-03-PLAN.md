---
phase: 06-domain-agents
plan: 03
type: execute
wave: 2
depends_on: ["06-01", "06-02"]
files_modified:
  - backend/app/agents/financial.py
  - backend/app/agents/legal.py
  - backend/app/agents/evidence.py
  - backend/app/agents/domain_runner.py
autonomous: true

must_haves:
  truths:
    - "Financial, Legal, and Evidence agents process files and produce structured output"
    - "Each agent accepts context_injection parameter and prepends it to the user message when provided"
    - "Domain runner spawns one agent instance per (group, agent_type) pair, where groups include both explicit file_groups and implicit single-file groups for ungrouped routing decisions"
    - "Multiple instances of the same agent type run concurrently with different file subsets and group-specific context"
    - "Stage session names include group identifier for uniqueness (e.g., financial_grp_0, financial_grp_1)"
    - "Agents execute in parallel via asyncio.gather with independent database sessions"
    - "Pro-to-Flash fallback works transparently with SSE fallback warning"
    - "Agent execution records logged to database with parent tracking"
    - "Partial results preserved when one agent fails"
    - "Results dict supports multiple results per agent type"
    - "compute_agent_tasks is the single source of truth for file-group iteration logic, used by both domain_runner and the pipeline"
  artifacts:
    - path: "backend/app/agents/financial.py"
      provides: "FinancialAgent class + run_financial function with context_injection param"
      contains: "async def run_financial"
    - path: "backend/app/agents/legal.py"
      provides: "LegalAgent class + run_legal function with context_injection param"
      contains: "async def run_legal"
    - path: "backend/app/agents/evidence.py"
      provides: "EvidenceAgent class + run_evidence function with context_injection param"
      contains: "async def run_evidence"
    - path: "backend/app/agents/domain_runner.py"
      provides: "compute_agent_tasks for pre-computing agent task list, run_domain_agents_parallel with file-group-based spawning returning dict[str, list[tuple[BaseModel | None, str]]]"
      contains: "async def run_domain_agents_parallel"
      exports: ["compute_agent_tasks", "run_domain_agents_parallel", "build_strategy_context"]
  key_links:
    - from: "backend/app/agents/domain_runner.py"
      to: "backend/app/agents/financial.py"
      via: "import and call run_financial per group"
      pattern: "from app.agents.financial import run_financial"
    - from: "backend/app/agents/domain_runner.py"
      to: "backend/app/schemas/agent.py"
      via: "import OrchestratorOutput, FileGroupForProcessing, RoutingDecision for routing"
      pattern: "from app.schemas.agent import OrchestratorOutput"
    - from: "backend/app/agents/financial.py"
      to: "backend/app/services/adk_service.py"
      via: "uses build_domain_agent_content, create_stage_runner, get_or_create_stage_session"
      pattern: "from app.services.adk_service import"
    - from: "backend/app/api/agents.py"
      to: "backend/app/agents/domain_runner.py"
      via: "import compute_agent_tasks for SSE pre-emission"
      pattern: "from app.agents.domain_runner import compute_agent_tasks"
---

<objective>
Implement the three parallel domain agents (Financial, Legal, Evidence) with context_injection support, and the file-group-based parallel execution orchestrator. Each agent follows the exact same pattern as `run_triage`/`run_orchestrator` with stage-isolated sessions, Pro-to-Flash fallback, and execution logging. The critical architectural change: domain_runner.py spawns one agent instance PER (file_group, agent_type) pair rather than one per agent type.

Purpose: These are the core analysis agents that extract domain-specific findings from case files. The file-group-based spawning means the orchestrator's grouping decisions directly control agent parallelism -- e.g., 2 financial groups spawn 2 concurrent Financial agents with different file subsets and group-specific context injection. This enables richer, more focused analysis per group.

Output: 3 domain agent modules (financial.py, legal.py, evidence.py) with context_injection parameter + 1 file-group-aware parallel runner module (domain_runner.py) with exported `compute_agent_tasks` helper.

**REQ-AGENT-007h note:** The ROADMAP references ResilientAgentWrapper, but per RESEARCH.md the resilience pattern is implemented as inline Pro-to-Flash fallback try/except within each run function (e.g., run_financial). This is functionally equivalent -- same retry-with-simpler-model behavior, just not wrapped in a separate class. A separate wrapper class adds indirection without benefit for our 4-agent setup.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-domain-agents/06-CONTEXT.md
@.planning/phases/06-domain-agents/06-RESEARCH.md

@backend/app/agents/triage.py
@backend/app/agents/orchestrator.py
@backend/app/agents/parsing.py
@backend/app/agents/factory.py
@backend/app/agents/base.py
@backend/app/schemas/agent.py
@backend/app/services/adk_service.py
@backend/app/services/agent_events.py
@backend/app/models/agent_execution.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Financial agent module with context_injection (template for other agents)</name>
  <files>
    backend/app/agents/financial.py
  </files>
  <action>
Create `backend/app/agents/financial.py` following the EXACT pattern from `triage.py` and `orchestrator.py`. This serves as the template that legal.py and evidence.py will mirror.

1. **ABOUTME header**: 2-line comment explaining the file.

2. **Imports**: Same as triage.py -- json, logging, datetime, UUID, Event, types, AsyncSession, PublishFn, AgentFactory, parsing helpers, get_settings, AgentExecution, AgentExecutionStatus, CaseFile, FinancialOutput, adk_service functions. Additionally import `build_domain_agent_content` from adk_service (NOT `build_agent_content`).

3. **Agent wrapper class** (`FinancialAgent`):
   - `__init__(self, case_id, model, publish_fn)` -- model parameter defaults to MODEL_PRO but accepts MODEL_FLASH for fallback
   - Creates agent via `AgentFactory.create_financial_agent(case_id, model=model, publish_fn=publish_fn)`
   - Has `agent` property

4. **Output parsing function** (`parse_financial_output`):
   - Same reverse-event-scan pattern as `parse_triage_output`
   - Uses `extract_json_from_text` from parsing.py
   - Returns `FinancialOutput | None`

5. **Content preparation function** (`_prepare_financial_content`):
   - Uses `build_domain_agent_content` (NOT `build_agent_content`) to force video/audio through File API
   - Prompt text: "Analyze the following documents for financial insights. Extract transactions, amounts, anomalies, and account relationships."
   - **NEW: context_injection handling** -- If `context_injection` is provided (non-None, non-empty string), prepend it to the prompt text before the analysis instruction:
     ```python
     prompt_parts: list[str] = []
     if context_injection:
         prompt_parts.append(f"--- CASE CONTEXT ---\n{context_injection}\n---\n")
     prompt_parts.append("Analyze the following documents for financial insights. Extract transactions, amounts, anomalies, and account relationships.")
     prompt = "\n".join(prompt_parts)
     ```

6. **Main execution function** (`run_financial`):
   Signature:
   ```python
   async def run_financial(
       case_id: str,
       workflow_id: str,
       user_id: str,
       files: list[CaseFile],
       hypotheses: list[dict[str, object]],
       db_session: AsyncSession,
       publish_event: PublishFn | None = None,
       parent_execution_id: UUID | None = None,
       context_injection: str | None = None,
       stage_suffix: str = "",
   ) -> FinancialOutput | None:
   ```

   **New parameters compared to old plan:**
   - `context_injection: str | None = None` -- case-specific framing from orchestrator. Passed through to `_prepare_financial_content`.
   - `stage_suffix: str = ""` -- appended to stage name for uniqueness when multiple instances of same agent type run concurrently. E.g., if stage_suffix="_grp_0", stages become "financial_grp_0" and "financial_grp_0_fallback".

   Implementation follows `run_triage` exactly but with Pro-to-Flash fallback (inline try/except -- this satisfies REQ-AGENT-007h resilience requirement without a separate wrapper class):

   a. Create execution record (PENDING) with `agent_name="financial"`, `model_name=settings.gemini_pro_model`. Include `"stage_suffix": stage_suffix` in input_data if stage_suffix is non-empty.
   b. Mark RUNNING with started_at
   c. Build multimodal content with `build_domain_agent_content`, passing context_injection. If hypotheses are non-empty, append a hypothesis context section to the prompt text: `\n\n--- EXISTING HYPOTHESES TO EVALUATE ---\n{json.dumps(hypotheses, indent=2)}`
   d. **Attempt 1 (Pro model):** Create agent with MODEL_PRO, create runner, create stage session (stage=f"financial{stage_suffix}"), run, parse output. Use MAX_PARSE_RETRIES = 1 (same as triage).
   e. **If Pro fails (parse failure after retries OR exception):** Attempt 2 with MODEL_FLASH as fallback. Create new agent with model=MODEL_FLASH, new runner, new stage session (stage=f"financial{stage_suffix}_fallback"). Log warning. Set a `_fallback_used` flag.
   f. If fallback was used, emit a fallback warning SSE event via `publish_event` if available:
      ```python
      if publish_event and fallback_used:
          _fire_fallback = publish_event(
              "AGENT_FALLBACK",
              {"case_id": case_id, "agent_name": "financial", "fallback_model": MODEL_FLASH},
          )
          if _fire_fallback is not None:
              asyncio.ensure_future(_fire_fallback)
      ```
   g. Update execution record with status, output_data, tokens, thinking_traces, completed_at. If fallback was used, add `"fallback_used": True, "fallback_model": MODEL_FLASH` to execution's output_data metadata.
   h. Return output or None.

   **IMPORTANT differences from triage:**
   - `hypotheses` parameter (list[dict]) for hypothesis evaluation context
   - `context_injection` parameter for case-specific framing (prepended to user message)
   - `stage_suffix` parameter for concurrent instance isolation
   - Pro-to-Flash fallback (triage only uses Flash, no fallback needed)
   - Uses `build_domain_agent_content` instead of `build_agent_content`
   - `parent_execution_id` links to orchestrator execution for audit chain
  </action>
  <verify>
Run from the backend directory:
1. `python -c "from app.agents.financial import run_financial, FinancialAgent, parse_financial_output; print('Financial agent module OK')"` -- imports work.
2. `python -c "import inspect; from app.agents.financial import run_financial; sig = inspect.signature(run_financial); assert 'hypotheses' in sig.parameters; assert 'context_injection' in sig.parameters; assert 'stage_suffix' in sig.parameters; print('All params exist')"` -- verify signature.
  </verify>
  <done>
Financial agent module created with: Agent wrapper class, output parser, content preparer using build_domain_agent_content with context_injection prepending, and run function with inline Pro-to-Flash fallback (REQ-AGENT-007h), hypothesis context injection, stage_suffix for concurrent instance isolation, stage-isolated sessions, and execution logging.
  </done>
</task>

<task type="auto">
  <name>Task 2: Legal and Evidence agent modules + file-group-based parallel runner with compute_agent_tasks</name>
  <files>
    backend/app/agents/legal.py
    backend/app/agents/evidence.py
    backend/app/agents/domain_runner.py
  </files>
  <action>
**2a. Create `backend/app/agents/legal.py` and `backend/app/agents/evidence.py`:**

Both follow the IDENTICAL pattern as financial.py (Task 1) with only these substitutions:

- legal.py: agent_name="legal", LegalAgent, LegalOutput, parse_legal_output, run_legal, stage=f"legal{stage_suffix}", stage_fallback=f"legal{stage_suffix}_fallback"
  - Prompt text: "Analyze the following documents for legal significance. Extract obligations, risks, compliance issues, and legal entities."
  - Same `context_injection: str | None = None` and `stage_suffix: str = ""` parameters

- evidence.py: agent_name="evidence", EvidenceAgent, EvidenceOutput, parse_evidence_output, run_evidence, stage=f"evidence{stage_suffix}", stage_fallback=f"evidence{stage_suffix}_fallback"
  - Prompt text: "Analyze the following documents as physical/digital evidence. Assess authenticity, chain of custody, and corroboration."
  - Same `context_injection: str | None = None` and `stage_suffix: str = ""` parameters

All three share the same inline Pro-to-Flash fallback pattern (REQ-AGENT-007h) and context_injection handling.

**2b. Create `backend/app/agents/domain_runner.py`:**

The file-group-based parallel execution coordinator for Financial, Legal, and Evidence agents.

**ABOUTME header**: "File-group-based parallel domain agent execution orchestrator." / "Spawns one agent instance per (file_group, agent_type) pair based on orchestrator routing."

**Key design: File-group-based spawning**

Instead of spawning one agent per agent type, the runner spawns one agent instance per (file_group, agent_type) pair. This means:
- If the orchestrator creates 2 financial file_groups, 2 separate Financial agent instances run concurrently
- Each instance gets a different file subset and group-specific context (from `FileGroupForProcessing.shared_context`)
- Files NOT in any explicit group become implicit single-file groups
- Context injection comes from two sources:
  1. `FileGroupForProcessing.shared_context` for files that are part of a group
  2. `RoutingDecision.context_injection` for individual file routing (ungrouped files)

**Key exported helper function: `compute_agent_tasks`**

This function is the SINGLE SOURCE OF TRUTH for file-group iteration logic. It is used by both `run_domain_agents_parallel` (for actual execution) and the pipeline in `agents.py` (for SSE event pre-emission). This eliminates duplication and ensures the pipeline always emits SSE events for exactly the agent tasks that will actually run.

```python
def compute_agent_tasks(
    routing: OrchestratorOutput,
    files: list[CaseFile],
) -> list[AgentTask]:
    """Compute the list of agent tasks that will be executed.

    This is the single source of truth for file-group iteration logic.
    Used by both run_domain_agents_parallel (for actual execution) and the
    pipeline (for SSE event pre-emission).

    Returns a list of AgentTask entries, one per (agent_type, group) pair.
    Each AgentTask contains agent_type, files, context_injection, stage_suffix,
    and group_label.
    """
    file_lookup: dict[str, CaseFile] = {str(f.id): f for f in files}
    tasks: list[AgentTask] = []
    grouped_file_ids: set[str] = set()

    # Explicit file_groups from orchestrator
    for grp_idx, group in enumerate(routing.file_groups):
        group_files = [file_lookup[fid] for fid in group.file_ids if fid in file_lookup]
        if not group_files:
            continue
        grouped_file_ids.update(group.file_ids)
        for agent_type in group.target_agents:
            if agent_type in ("financial", "legal", "evidence"):
                tasks.append(AgentTask(
                    agent_type=agent_type,
                    files=group_files,
                    context_injection=group.shared_context,
                    stage_suffix=f"_grp_{grp_idx}",
                    group_label=f"grp_{grp_idx}",
                ))

    # Ungrouped files become implicit single-file groups
    ungrouped_idx = 0
    for decision in routing.routing_decisions:
        if decision.file_id in grouped_file_ids:
            continue
        file = file_lookup.get(decision.file_id)
        if not file:
            continue
        for agent_type in decision.target_agents:
            if agent_type in ("financial", "legal", "evidence"):
                tasks.append(AgentTask(
                    agent_type=agent_type,
                    files=[file],
                    context_injection=decision.context_injection,
                    stage_suffix=f"_ungrouped_{ungrouped_idx}",
                    group_label=f"ungrouped_{ungrouped_idx}",
                ))
        ungrouped_idx += 1

    return tasks
```

**AgentTask dataclass** (defined in same file, above the function):

```python
@dataclass
class AgentTask:
    agent_type: str
    files: list[CaseFile]
    context_injection: str | None
    stage_suffix: str  # e.g., "_grp_0", "_ungrouped_2"
    group_label: str   # e.g., "grp_0", "ungrouped_2"
```

**Key function: `run_domain_agents_parallel`**

```python
async def run_domain_agents_parallel(
    case_id: str,
    workflow_id: str,
    user_id: str,
    routing: OrchestratorOutput,
    files: list[CaseFile],
    hypotheses: list[dict[str, object]],
    db_session_factory: Callable[..., AsyncContextManager[AsyncSession]],
    publish_event: PublishFn | None = None,
    orchestrator_execution_id: UUID | None = None,
) -> dict[str, list[tuple[BaseModel | None, str]]]:
```

**Return type:** Returns `dict[str, list[tuple[BaseModel | None, str]]]` where:
- Key: agent type name (e.g., "financial", "legal", "evidence")
- Value: list of (result, group_label) tuples -- one per group that ran for that agent type
- `group_label`: human-readable identifier like "grp_0", "grp_1", or "ungrouped_0"

This supports multiple results per agent type while maintaining traceability.

**Implementation:**

1. **Call `compute_agent_tasks` to get the task list** (no inline iteration logic -- delegate to the shared helper):

   ```python
   tasks = compute_agent_tasks(routing, files)
   ```

2. **Create async wrapper for each agent task** that manages its own database session:

   Each parallel agent MUST create its own database session from the session factory (per RESEARCH.md Pitfall 3). Do NOT share the caller's session.

   ```python
   RUN_FNS: dict[str, Callable] = {
       "financial": run_financial,
       "legal": run_legal,
       "evidence": run_evidence,
   }

   async def _run_agent_with_session(
       task: AgentTask,
   ) -> tuple[str, BaseModel | None, str]:
       """Returns (agent_type, result, group_label)."""
       run_fn = RUN_FNS[task.agent_type]
       async with db_session_factory() as db:
           result = await run_fn(
               case_id=case_id,
               workflow_id=workflow_id,
               user_id=user_id,
               files=task.files,
               hypotheses=hypotheses,
               db_session=db,
               publish_event=publish_event,
               parent_execution_id=orchestrator_execution_id,
               context_injection=task.context_injection,
               stage_suffix=task.stage_suffix,
           )
           await db.commit()
           return task.agent_type, result, task.group_label
   ```

3. **Launch ALL tasks concurrently** (multiple tasks for same agent type run in parallel):
   ```python
   if not tasks:
       return {}

   coros = [_run_agent_with_session(t) for t in tasks]
   results = await asyncio.gather(*coros, return_exceptions=True)
   ```

4. **Map results back, grouped by agent type:**
   ```python
   output: dict[str, list[tuple[BaseModel | None, str]]] = {}
   for item in results:
       if isinstance(item, Exception):
           logger.error("Domain agent task failed: %s", item)
           continue
       agent_type, result, group_label = item
       if agent_type not in output:
           output[agent_type] = []
       output[agent_type].append((result, group_label))
   return output
   ```

5. **Log summary** of what ran: total tasks, per-agent-type counts, successes, failures.

**Also add a helper function: `build_strategy_context`**

```python
def build_strategy_context(
    domain_results: dict[str, list[tuple[BaseModel | None, str]]],
) -> str:
    """Build text summaries of domain agent findings for the Strategy agent.

    Strategy agent receives TEXT summaries (not raw files) from other
    domain agents, per CONTEXT.md decision and RESEARCH.md Pitfall 4.

    Handles the new multi-result-per-agent structure: iterates over
    all (result, group_label) pairs for each agent type.
    """
```

This function iterates over domain_results and for each agent type, for each (result, group_label) pair:
- Skips None results
- Extracts the agent name, group label, and finding count
- For each finding: category, title, confidence, and first sentence of description
- Produces a structured text summary like:
  ```
  --- Financial Agent Findings (grp_0, 5 findings) ---
  [Transactions] Invoice Discrepancy (confidence: 78): Invoice amounts for Acme Corp...
  [Anomalies] Round-Tripping Pattern (confidence: 62): Funds appear to cycle through...
  ...

  --- Financial Agent Findings (grp_1, 3 findings) ---
  [Valuations] Asset Overvaluation (confidence: 55): Property at 123 Main St...
  ...
  ```

This summary is what gets injected into the Strategy agent's context (Plan 04 consumes this).

**Type imports needed:** Use `from collections.abc import Callable` and `from contextlib import AbstractAsyncContextManager as AsyncContextManager` for the session factory. Use `from dataclasses import dataclass` for AgentTask.
  </action>
  <verify>
Run from the backend directory:
1. `python -c "from app.agents.legal import run_legal, LegalAgent, parse_legal_output; print('Legal agent module OK')"` -- imports work.
2. `python -c "from app.agents.evidence import run_evidence, EvidenceAgent, parse_evidence_output; print('Evidence agent module OK')"` -- imports work.
3. `python -c "from app.agents.domain_runner import run_domain_agents_parallel, build_strategy_context, compute_agent_tasks; print('domain_runner imports OK')"` -- imports work, including compute_agent_tasks.
4. `python -c "import inspect; from app.agents.domain_runner import run_domain_agents_parallel; sig = inspect.signature(run_domain_agents_parallel); assert 'db_session_factory' in sig.parameters; print('session factory param exists')"` -- verify session factory parameter.
5. `python -c "from app.agents.domain_runner import build_strategy_context; result = build_strategy_context({}); print(f'Empty context: {repr(result)}')"` -- works with empty input.
6. `python -c "import inspect; from app.agents.domain_runner import compute_agent_tasks; sig = inspect.signature(compute_agent_tasks); assert 'routing' in sig.parameters; assert 'files' in sig.parameters; print('compute_agent_tasks signature OK')"` -- verify compute_agent_tasks signature.
7. `python -c "import inspect; from app.agents.legal import run_legal; sig = inspect.signature(run_legal); assert 'context_injection' in sig.parameters; assert 'stage_suffix' in sig.parameters; print('Legal has context_injection and stage_suffix')"` -- verify legal signature.
8. `python -c "import inspect; from app.agents.evidence import run_evidence; sig = inspect.signature(run_evidence); assert 'context_injection' in sig.parameters; assert 'stage_suffix' in sig.parameters; print('Evidence has context_injection and stage_suffix')"` -- verify evidence signature.
  </verify>
  <done>
Legal and Evidence agent modules created following financial.py template (same inline Pro-to-Flash fallback for REQ-AGENT-007h, same context_injection and stage_suffix params). domain_runner.py created with:
- `compute_agent_tasks`: Exported pure function that computes (agent_type, group_label, files) triples from routing. Single source of truth for file-group iteration logic, used by both run_domain_agents_parallel and the pipeline's SSE pre-emission.
- `run_domain_agents_parallel`: Calls compute_agent_tasks internally, then spawns one agent instance per task with independent DB sessions. Returns `dict[str, list[tuple[BaseModel | None, str]]]` supporting multiple results per agent type.
- `build_strategy_context`: Converts multi-result domain agent outputs to text summaries for Strategy agent consumption, including group labels for traceability.
  </done>
</task>

</tasks>

<verification>
- All 3 domain agent modules follow the same pattern as triage.py
- Each has: Agent class, output parser, content preparer with context_injection, run function with Pro-to-Flash fallback + context_injection + stage_suffix
- domain_runner.py orchestrates file-group-based parallel execution with independent DB sessions
- compute_agent_tasks is the single source of truth for file-group iteration logic (no duplication in agents.py)
- Explicit file_groups from orchestrator create grouped agent tasks with shared_context as context_injection
- Ungrouped files (in routing_decisions but not in file_groups) become implicit single-file groups with RoutingDecision.context_injection
- Multiple instances of same agent type run concurrently (e.g., 2 Financial agents for 2 groups)
- Stage names include group suffix for uniqueness (financial_grp_0, financial_grp_1)
- Hypothesis context injected into agent prompts when available
- Fallback usage tracked in execution records and SSE events
- build_strategy_context produces text summaries handling multi-result structure
</verification>

<success_criteria>
- `run_financial`, `run_legal`, `run_evidence` all importable and have context_injection + stage_suffix params
- `compute_agent_tasks` exported and importable from domain_runner, returns list of AgentTask
- `run_domain_agents_parallel` calls compute_agent_tasks internally (no duplicated iteration logic)
- Return type is `dict[str, list[tuple[BaseModel | None, str]]]` (multiple results per agent type)
- Parallel execution uses asyncio.gather with return_exceptions=True
- Each parallel agent creates its own DB session (no shared session)
- Stage names include group suffix (e.g., financial_grp_0) for session uniqueness
- Context injection from shared_context (groups) and context_injection (individual decisions) flows through
- Pro-to-Flash fallback implemented inline in each run function (REQ-AGENT-007h)
- `build_strategy_context` converts multi-result domain outputs to readable text summaries with group labels
- All execution records track parent_execution_id for audit chain
</success_criteria>

<output>
After completion, create `.planning/phases/06-domain-agents/06-03-SUMMARY.md`
</output>
