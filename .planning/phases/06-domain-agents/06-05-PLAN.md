---
phase: 06-domain-agents
plan: 05
type: execute
wave: 3
depends_on: ["06-03", "06-04"]
files_modified:
  - backend/app/api/agents.py
  - backend/app/services/agent_events.py
autonomous: true

must_haves:
  truths:
    - "Full pipeline runs: Triage -> Orchestrator -> Parallel Domain Agents -> Strategy -> processing-complete"
    - "Each domain agent emits agent-started and agent-complete SSE events with metadata"
    - "Low-confidence findings trigger HITL confirmation via the existing confirmation service"
    - "HITL confirmation flow works end-to-end: finding -> SSE event -> user responds -> pipeline continues"
    - "Pipeline status endpoint reflects domain_analysis stage"
    - "Partial domain agent failures don't crash the pipeline"
    - "File statuses transition correctly through the extended pipeline"
    - "Fallback usage visible in SSE events"
  artifacts:
    - path: "backend/app/api/agents.py"
      provides: "Extended run_analysis_workflow with domain agent stages 3 and 4"
      contains: "run_domain_agents_parallel"
    - path: "backend/app/services/agent_events.py"
      provides: "emit_agent_fallback helper for fallback warning events"
      contains: "emit_agent_fallback"
  key_links:
    - from: "backend/app/api/agents.py"
      to: "backend/app/agents/domain_runner.py"
      via: "import and call run_domain_agents_parallel"
      pattern: "from app.agents.domain_runner import run_domain_agents_parallel"
    - from: "backend/app/api/agents.py"
      to: "backend/app/agents/strategy.py"
      via: "import and call run_strategy"
      pattern: "from app.agents.strategy import run_strategy"
    - from: "backend/app/api/agents.py"
      to: "backend/app/services/confirmation.py"
      via: "import request_confirmation for HITL"
      pattern: "from app.services.confirmation import request_confirmation"
---

<objective>
Wire the domain agents into the analysis pipeline, add SSE event emission for domain agent lifecycle, integrate HITL confirmation for low-confidence findings, and update the pipeline status endpoint. This completes the Phase 6 backend implementation.

Purpose: This is the integration plan that connects all the pieces built in Plans 01-04 into the working pipeline. After this plan, uploading files and starting analysis will trigger the full pipeline through domain agents.

Output: Extended `agents.py` pipeline with stages 3-4 (domain + strategy), HITL integration, SSE events for all domain agents.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-domain-agents/06-CONTEXT.md
@.planning/phases/06-domain-agents/06-RESEARCH.md

@backend/app/api/agents.py
@backend/app/services/agent_events.py
@backend/app/services/confirmation.py
@backend/app/agents/domain_runner.py
@backend/app/agents/strategy.py
@backend/app/agents/base.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire domain agents into pipeline and add SSE events</name>
  <files>
    backend/app/api/agents.py
    backend/app/services/agent_events.py
  </files>
  <action>
**1a. Add `emit_agent_fallback` to `agent_events.py`:**

Add a new convenience emitter for fallback warnings:

```python
async def emit_agent_fallback(
    case_id: str,
    agent_type: str,
    fallback_model: str,
    reason: str | None = None,
) -> None:
    """Emit a thinking-update event indicating an agent fell back to a simpler model.

    Rendered as a warning badge on the agent node in the Command Center.
    Uses thinking-update event type since the frontend already handles it.

    Args:
        case_id: UUID string of the case.
        agent_type: Agent type that fell back (e.g., "financial").
        fallback_model: Name of the fallback model used.
        reason: Optional reason for the fallback.
    """
    warning_text = f"[FALLBACK] Agent switched to {fallback_model}"
    if reason:
        warning_text += f": {reason}"

    await publish_agent_event(
        case_id,
        AgentEventType.THINKING_UPDATE,
        {
            "type": AgentEventType.THINKING_UPDATE.value,
            "agentType": agent_type,
            "thought": warning_text,
            "timestamp": datetime.now(tz=UTC).isoformat(),
            "isFallback": True,
            "fallbackModel": fallback_model,
        },
    )
```

Add the `datetime` import at the top if not already present: `from datetime import UTC, datetime`

**1b. Extend `run_analysis_workflow` in `agents.py`:**

Add new imports at the top of agents.py:
```python
from app.agents.domain_runner import run_domain_agents_parallel, build_strategy_context
from app.agents.strategy import run_strategy
from app.agents.base import CONFIDENCE_THRESHOLD
from app.services.confirmation import request_confirmation
from app.database import _get_sessionmaker
```

After the orchestrator stage (after `emit_agent_complete` for orchestrator, around line 393 where "Step 6: Update file statuses to ANALYZED" currently is), insert the following stages. Move the file status update and processing-complete to AFTER all domain agents finish.

**Stage 3: Parallel Domain Agents**

```python
# ---- Stage 3: Domain Agents (Parallel) ----
domain_results: dict[str, BaseModel | None] = {}

if orchestrator_output:
    logger.info(
        "Pipeline starting stage=domain_agents case=%s workflow=%s",
        case_id, workflow_id,
    )

    # Query orchestrator execution for parent chain
    orch_exec_result = await db.execute(
        select(AgentExecution)
        .where(
            AgentExecution.workflow_id == UUID(workflow_id),
            AgentExecution.agent_name == "orchestrator",
        )
        .order_by(AgentExecution.created_at.desc())
        .limit(1)
    )
    orch_execution = orch_exec_result.scalar_one_or_none()

    # Emit agent-started for each domain agent that will run
    domain_agents_to_run = set()
    for rd in orchestrator_output.routing_decisions:
        for agent_name in rd.target_agents:
            if agent_name in ("financial", "legal", "evidence"):
                domain_agents_to_run.add(agent_name)

    domain_task_ids: dict[str, str] = {}
    for agent_name in domain_agents_to_run:
        task_id = str(uuid4())
        domain_task_ids[agent_name] = task_id
        await emit_agent_started(
            case_id=case_id,
            agent_type=agent_name,
            task_id=task_id,
            file_id=str(first_file.id),
            file_name=f"{agent_name}-analysis",
        )

    # Run parallel domain agents (each creates own DB session)
    domain_results = await run_domain_agents_parallel(
        case_id=case_id,
        workflow_id=workflow_id,
        user_id=user_id,
        routing=orchestrator_output,
        files=files,
        hypotheses=[],  # Empty until hypothesis system exists (Phase 7)
        db_session_factory=session_factory,
        publish_event=publish_fn,
        orchestrator_execution_id=orch_execution.id if orch_execution else None,
    )

    # Emit agent-complete/error for each domain agent
    for agent_name in domain_agents_to_run:
        task_id = domain_task_ids[agent_name]
        result = domain_results.get(agent_name)

        if result is not None:
            # Query execution record for metadata
            exec_result = await db.execute(
                select(AgentExecution)
                .where(
                    AgentExecution.workflow_id == UUID(workflow_id),
                    AgentExecution.agent_name == agent_name,
                )
                .order_by(AgentExecution.created_at.desc())
                .limit(1)
            )
            agent_exec = exec_result.scalar_one_or_none()
            agent_metadata = (
                _build_execution_metadata(agent_exec, settings.gemini_pro_model)
                if agent_exec else {}
            )

            finding_count = len(result.findings) if hasattr(result, 'findings') else 0
            entity_count = len(result.entities) if hasattr(result, 'entities') else 0

            await emit_agent_complete(
                case_id=case_id,
                agent_type=agent_name,
                task_id=task_id,
                result={
                    "taskId": task_id,
                    "agentType": agent_name,
                    "outputs": [
                        {
                            "type": f"{agent_name}-findings",
                            "data": {
                                "findingCount": finding_count,
                                "entityCount": entity_count,
                            },
                        }
                    ],
                    "metadata": agent_metadata,
                },
            )
        else:
            await emit_agent_error(
                case_id=case_id,
                agent_type=agent_name,
                task_id=task_id,
                error=f"{agent_name} agent failed to produce output",
            )
```

**Stage 4: Strategy Agent (Sequential)**

```python
# ---- Stage 4: Legal Strategy Agent (Sequential, after domain agents) ----
strategy_result = None
any_domain_ran = any(v is not None for v in domain_results.values())

if orchestrator_output and any_domain_ran:
    logger.info(
        "Pipeline starting stage=strategy case=%s workflow=%s",
        case_id, workflow_id,
    )

    # Build text summaries of domain agent findings
    domain_summaries = build_strategy_context(domain_results)

    # Find strategy-routed files
    strategy_file_ids = set()
    for rd in orchestrator_output.routing_decisions:
        if "strategy" in rd.target_agents:
            strategy_file_ids.add(rd.file_id)

    file_lookup = {str(f.id): f for f in files}
    strategy_files = [file_lookup[fid] for fid in strategy_file_ids if fid in file_lookup]

    strategy_task_id = str(uuid4())
    await emit_agent_started(
        case_id=case_id,
        agent_type="strategy",
        task_id=strategy_task_id,
        file_id=str(first_file.id),
        file_name="strategy-analysis",
    )

    strategy_result = await run_strategy(
        case_id=case_id,
        workflow_id=workflow_id,
        user_id=user_id,
        files=strategy_files,
        domain_summaries=domain_summaries,
        hypotheses=[],
        db_session=db,
        publish_event=publish_fn,
        parent_execution_id=orch_execution.id if orch_execution else None,
    )

    if strategy_result:
        # Query strategy execution for metadata
        strat_exec_result = await db.execute(
            select(AgentExecution)
            .where(
                AgentExecution.workflow_id == UUID(workflow_id),
                AgentExecution.agent_name == "strategy",
            )
            .order_by(AgentExecution.created_at.desc())
            .limit(1)
        )
        strat_exec = strat_exec_result.scalar_one_or_none()
        strat_metadata = (
            _build_execution_metadata(strat_exec, settings.gemini_pro_model)
            if strat_exec else {}
        )

        await emit_agent_complete(
            case_id=case_id,
            agent_type="strategy",
            task_id=strategy_task_id,
            result={
                "taskId": strategy_task_id,
                "agentType": "strategy",
                "outputs": [
                    {
                        "type": "strategy-findings",
                        "data": {
                            "findingCount": len(strategy_result.findings),
                        },
                    }
                ],
                "metadata": strat_metadata,
            },
        )
        domain_results["strategy"] = strategy_result
    else:
        await emit_agent_error(
            case_id=case_id,
            agent_type="strategy",
            task_id=strategy_task_id,
            error="Strategy agent failed to produce output",
        )
```

**Stage 5: HITL Confirmation for Low-Confidence Findings**

After domain agents complete and before file status update:

```python
# ---- Stage 5: HITL for Low-Confidence Findings ----
if domain_results:
    for agent_name, result in domain_results.items():
        if result is None or not hasattr(result, 'findings'):
            continue
        for finding in result.findings:
            if finding.confidence < CONFIDENCE_THRESHOLD:
                logger.info(
                    "Low-confidence finding from %s: %s (confidence=%s), requesting HITL",
                    agent_name, finding.title, finding.confidence,
                )
                confirmation_result = await request_confirmation(
                    case_id=case_id,
                    agent_type=agent_name,
                    action_description=(
                        f"Low-confidence finding ({finding.confidence}/100): {finding.title}"
                    ),
                    affected_items=[c.file_id for c in finding.citations],
                    context={
                        "finding_title": finding.title,
                        "finding_category": finding.category,
                        "finding_description": finding.description[:500],
                        "confidence": finding.confidence,
                        "agent": agent_name,
                    },
                )
                if not confirmation_result.approved:
                    logger.info(
                        "Finding rejected by user: %s from %s (reason: %s)",
                        finding.title, agent_name, confirmation_result.reason,
                    )
                    # Mark finding as rejected (for audit trail)
                    # Finding remains in output but will be excluded from KG in Phase 7
```

**Update file status and processing-complete:**

Move the existing file status update to ANALYZED and emit_processing_complete to AFTER all stages complete. Update the entity count and relationship count:

```python
# Count findings and entities across all domain agents
total_findings = 0
total_domain_entities = 0
for result in domain_results.values():
    if result is not None and hasattr(result, 'findings'):
        total_findings += len(result.findings)
    if result is not None and hasattr(result, 'entities'):
        total_domain_entities += len(result.entities)
```

Use `total_domain_entities + total_entities` (triage entities) in the `emit_processing_complete` call. Use `total_findings` as additional metadata if desired.

**Update `get_analysis_status` endpoint:**

Update the status derivation logic to include domain agent stages. Check for domain agent executions in the workflow:
- If any domain agent execution is RUNNING -> status = "domain_analysis"
- If all domain agents COMPLETED -> continue to check strategy
- Add "strategy" stage if strategy execution exists

**1c. Update `AnalysisStatusResponse` to include domain results:**

Add an optional field:
```python
domain_results_summary: dict[str, int] | None = Field(
    default=None,
    description="Summary of domain agent findings: agent_name -> finding_count",
)
```

Populate from domain agent execution records when querying status.

**IMPORTANT:** Do NOT move or modify the existing triage and orchestrator stages. Only ADD code after the orchestrator stage and adjust where the file status update / processing-complete happen.
  </action>
  <verify>
1. `python -c "from app.api.agents import run_analysis_workflow; print('Pipeline imports OK')"` -- no import errors.
2. `python -c "from app.services.agent_events import emit_agent_fallback; print('Fallback emitter OK')"` -- new helper importable.
3. Review that the pipeline stages are: Triage -> Orchestrator -> Parallel Domain -> Strategy -> HITL -> Status Update -> Processing Complete.
4. `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes/backend && python -m py_compile app/api/agents.py && echo "Compilation OK"` -- no syntax errors.
  </verify>
  <done>
Full pipeline wired: Triage -> Orchestrator -> Parallel Domain Agents (Financial/Legal/Evidence) -> Strategy -> HITL for low-confidence findings -> File status update -> Processing complete SSE event. Each domain agent emits started/complete/error SSE events. Fallback warning events emitted when Pro->Flash switch occurs. Pipeline status endpoint reflects domain_analysis stage.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete Phase 6 domain agent pipeline:
- 4 domain agents (Financial, Legal, Evidence, Strategy) with Pydantic schemas, prompts, execution functions
- Parallel execution via asyncio.gather with independent DB sessions
- Pro-to-Flash fallback with SSE warning events
- HITL confirmation for low-confidence findings
- Full pipeline integration (Triage -> Orchestrator -> Domain -> Strategy -> HITL -> Complete)
  </what-built>
  <how-to-verify>
1. Start the backend: `cd backend && python -m uvicorn app.main:app --reload`
2. Upload 1-2 evidence files to a case via the frontend Case Library
3. Start analysis by clicking the analysis button (or `curl -X POST http://localhost:8000/api/cases/{case_id}/analyze -H "Authorization: Bearer {token}"`)
4. Open the Command Center page for the case
5. Verify in the Command Center:
   - Triage node lights up (processing -> complete)
   - Orchestrator node lights up (processing -> complete)
   - Domain agent nodes appear and light up (financial, legal, evidence -- whichever are routed)
   - Strategy node appears after domain agents complete
   - Thinking traces stream in real-time for each agent
   - If any agent falls back to Flash, a warning appears in the thinking trace
6. Check backend logs for:
   - "Pipeline starting stage=domain_agents" log line
   - "Pipeline starting stage=strategy" log line
   - Domain agent completion logs with duration and token counts
   - Any HITL confirmation triggers (if findings have low confidence)
7. Check analysis status endpoint: `curl http://localhost:8000/api/cases/{case_id}/analysis/{workflow_id}` -- should show domain_results_summary
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
- Pipeline runs end-to-end: Triage -> Orchestrator -> Domain Agents -> Strategy -> Complete
- SSE events emitted for all agent lifecycle stages
- Low-confidence findings trigger HITL confirmation modal
- Fallback events appear when Pro model fails
- Pipeline status endpoint shows correct stage
- Partial failures in domain agents don't crash pipeline
- File statuses correctly transition to ANALYZED after all agents complete
</verification>

<success_criteria>
- Upload files, start analysis, and see all 6 agent types (triage, orchestrator, financial, legal, evidence, strategy) execute in the Command Center
- Each agent shows in the decision tree with thinking traces, token counts, and timing
- Strategy agent runs AFTER parallel agents and incorporates their summaries
- Any low-confidence findings pause the pipeline for user confirmation
- Pipeline completes successfully even if one domain agent fails
- Analysis status endpoint returns domain_results_summary
</success_criteria>

<output>
After completion, create `.planning/phases/06-domain-agents/06-05-SUMMARY.md`
</output>
