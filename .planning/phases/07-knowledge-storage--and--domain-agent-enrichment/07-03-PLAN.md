---
phase: 07-knowledge-storage-and-domain-agent-enrichment
plan: 03
type: execute
wave: 2
depends_on: ["07-01", "07-02"]
files_modified:
  - backend/app/services/kg_builder.py
  - backend/app/services/findings_service.py
  - backend/pyproject.toml
autonomous: true

must_haves:
  truths:
    - "KG Builder reads domain agent output_data from agent_executions and extracts ALL entities without filtering or discarding"
    - "KG Builder creates relationship edges between entities co-occurring in the same finding"
    - "Entity deduplication auto-merges exact matches (name_normalized + entity_type) and flags fuzzy matches (>85% similarity) for later LLM resolution"
    - "Merged entities use soft merge via merged_into_id (no hard deletes)"
    - "Findings service saves each domain agent finding to case_findings with citations and entity_ids"
    - "Full-text search on case_findings works via plainto_tsquery"
    - "Degree computation updates entity connection counts"
  artifacts:
    - path: "backend/app/services/kg_builder.py"
      provides: "Programmatic KG Builder: entity extraction, relationship inference, deduplication, degree computation"
      contains: "async def build_knowledge_graph"
    - path: "backend/app/services/findings_service.py"
      provides: "case_findings storage and full-text search"
      contains: "async def save_findings_from_output"
  key_links:
    - from: "backend/app/services/kg_builder.py"
      to: "backend/app/models/knowledge_graph.py"
      via: "ORM model creation"
      pattern: "KgEntity\\("
    - from: "backend/app/services/kg_builder.py"
      to: "backend/app/schemas/agent.py"
      via: "Reading DomainEntity from output"
      pattern: "DomainEntity"
    - from: "backend/app/services/findings_service.py"
      to: "backend/app/models/findings.py"
      via: "ORM model creation"
      pattern: "CaseFinding\\("
---

<objective>
Implement the programmatic KG Builder service and findings storage service.

Purpose: The KG Builder is the core programmatic (non-LLM) service that transforms domain agent structured output into knowledge graph entities and relationships. The findings service persists each finding for downstream search and display. Together they bridge the gap between agent output and queryable knowledge.

Output: 2 new service files, 1 dependency added (rapidfuzz).
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-knowledge-storage--and--domain-agent-enrichment/07-RESEARCH.md
@.planning/phases/07-knowledge-storage--and--domain-agent-enrichment/07-CONTEXT.md
@backend/app/schemas/agent.py
@backend/app/models/knowledge_graph.py
@backend/app/models/findings.py
@backend/app/agents/domain_agent_runner.py
@backend/app/services/pipeline.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install rapidfuzz and implement KG Builder service</name>
  <files>
    backend/pyproject.toml
    backend/app/services/kg_builder.py
  </files>
  <action>
    First, install rapidfuzz: `cd backend && uv add rapidfuzz`

    Then create `backend/app/services/kg_builder.py` with 2-line ABOUTME comment.

    Follow the service pattern from `file_service.py` -- standalone async functions taking DB session as parameter, explicit logging.

    **Core functions:**

    1. `normalize_entity_name(name: str) -> str` -- Strips whitespace, lowercases, removes punctuation via `str.translate(str.maketrans("", "", string.punctuation))`. Used for deduplication matching.

    2. `async def extract_entities_from_output(output: BaseModel, agent_type: str, execution_id: UUID, case_id: UUID, db: AsyncSession) -> list[KgEntity]` -- The main entity extraction function.
       - Receives the ALREADY-PARSED Pydantic BaseModel object directly from domain_results (NOT raw output_data dict). The pipeline passes these objects directly -- no re-parsing needed.
       - Extract ALL entities from:
         a. Top-level `output.entities` list (if hasattr)
         b. Per-finding `finding.entities` lists (iterate output.findings, if hasattr)
       - For EACH entity, create a KgEntity row: name=entity.value, name_normalized=normalize_entity_name(entity.value), entity_type=entity.type, domain=agent_type, confidence=entity.confidence, metadata={m.key: m.value for m in entity.metadata} if entity.metadata else None, context=entity.context, source_execution_id=execution_id, source_finding_index=idx.
       - db.add() each entity, then await db.flush() to get IDs.
       - NEVER filter or discard entities. Log count.
       - Return the list of created KgEntity objects.

    3. `async def build_relationships_from_findings(output: BaseModel, agent_type: str, execution_id: UUID, case_id: UUID, entity_map: dict[str, UUID], db: AsyncSession) -> list[KgRelationship]` -- Infer relationships from co-occurrence.
       - Receives the ALREADY-PARSED Pydantic BaseModel object directly (same as extract_entities_from_output).
       - entity_map: maps normalized_name to entity_id (built from extract_entities_from_output results).
       - For each finding in output.findings, collect all entity names referenced.
       - For every pair of entities within the same finding, create a KgRelationship if one doesn't already exist for this pair+case.
       - relationship_type: infer from domain (e.g., "co_mentioned_in_{category}"). Label: "{entity_a} - {entity_b} ({finding.category})".
       - strength: start at 20 per co-occurrence. If entities co-occur in multiple findings, increase by 20 each time (capped at 100). Use a local dict to track cumulative strength before writing.
       - db.add() each relationship, flush.
       - Return created relationships.

    4. `async def deduplicate_entities(case_id: UUID, db: AsyncSession) -> tuple[int, int]` -- Entity deduplication pass.
       - Query all KgEntity rows for case_id where merged_into_id IS NULL.
       - Group by (entity_type) -- cross-domain merging allowed per CONTEXT.md decision. Do NOT group by domain.
       - For exact matches (same name_normalized within same entity_type): pick the entity with lowest created_at as primary. Set merged_into_id on duplicates. Increment merge_count on primary. Update kg_relationships pointing to duplicates to point to primary.
       - For fuzzy matches: use `rapidfuzz.fuzz.ratio(a.name_normalized, b.name_normalized)`. If >= 85, record as fuzzy match in a list (do NOT auto-merge). Log these for Phase 8 LLM resolution.
       - Return tuple of (exact_merges_count, fuzzy_flags_count).

    5. `async def compute_entity_degrees(case_id: UUID, db: AsyncSession) -> None` -- Update degree column.
       - For each entity where merged_into_id IS NULL, count relationships where entity is source or target.
       - Update degree column. Use a single SQL query with subquery or window function for efficiency:
         ```python
         from sqlalchemy import func, case as sa_case, or_
         # Query relationship counts per entity
         # Update degrees in bulk
         ```

    6. `async def build_knowledge_graph(case_id: str, workflow_id: str, domain_results: dict[str, list[tuple[BaseModel | None, str]]], db: AsyncSession) -> tuple[int, int, int]` -- Top-level orchestrator.
       - **domain_results shape:** `dict[str, list[tuple[BaseModel | None, str]]]` where key is agent_type (e.g., "financial", "legal", "evidence", "strategy"), and value is a list of (parsed_output, group_label) tuples. The parsed_output is a Pydantic BaseModel (e.g., FinancialOutput, LegalOutput) or None if that agent run failed.
       - NOTE: The caller (pipeline.py) is responsible for adding strategy_result into domain_results before calling this function. This function does NOT accept a separate strategy_result parameter.
       - For each agent_type and its results in domain_results:
         - For each (domain_output, grp_label) in results, skip if domain_output is None.
         - Query the AgentExecution record to get execution_id:
           ```python
           exec_result = await db.execute(
               select(AgentExecution)
               .where(
                   AgentExecution.workflow_id == UUID(workflow_id),
                   AgentExecution.agent_name == agent_type,
               )
               .order_by(AgentExecution.created_at.desc())
               .limit(1)
           )
           agent_exec = exec_result.scalar_one_or_none()
           execution_id = agent_exec.id if agent_exec else None
           ```
         - Call extract_entities_from_output with the BaseModel object directly.
         - Build entity_map from results (name_normalized -> entity.id).
         - Call build_relationships_from_findings with the BaseModel object directly.
       - After all agents processed, call deduplicate_entities.
       - Call compute_entity_degrees.
       - Return (entities_created, relationships_created, exact_merges).

    **Important design notes:**
    - Use `from __future__ import annotations` for forward references.
    - Import Pydantic models lazily inside functions to avoid circular imports (follow pipeline.py pattern).
  </action>
  <verify>
    Run `cd backend && python -c "from app.services.kg_builder import build_knowledge_graph, normalize_entity_name, deduplicate_entities; print('KG Builder importable')"` to confirm no import errors.

    Run `cd backend && python -c "from app.services.kg_builder import normalize_entity_name; assert normalize_entity_name('  John Q. Public  ') == 'john q public'; print('Normalization works')"` to test the normalizer.

    Run `cd backend && python -c "import rapidfuzz; print(f'rapidfuzz {rapidfuzz.__version__} installed')"` to confirm dependency.
  </verify>
  <done>KG Builder service with entity extraction, relationship inference, deduplication, and degree computation. rapidfuzz installed.</done>
</task>

<task type="auto">
  <name>Task 2: Implement findings storage service with full-text search</name>
  <files>
    backend/app/services/findings_service.py
  </files>
  <action>
    Create `backend/app/services/findings_service.py` with 2-line ABOUTME comment.

    **NOTE on vector search:** CONTEXT.md specifies Vertex AI vector search, but per the ROADMAP this is deferred to Phase 9. This service implements PostgreSQL tsvector full-text search as the v1 search layer. Add a comment at the top of the file: `# NOTE: v1 search uses PG tsvector. Vertex AI vector search (gemini-embedding-001) deferred to Phase 9.`

    **Core functions:**

    1. `async def save_findings_from_output(output: BaseModel, agent_type: str, execution_id: UUID, case_id: UUID, workflow_id: UUID, file_group_label: str, db: AsyncSession) -> list[CaseFinding]` -- Saves findings from a domain agent output.
       - Receives the ALREADY-PARSED Pydantic BaseModel object directly from domain_results (NOT raw output_data dict). The pipeline passes these objects directly.
       - For each finding in output.findings (if hasattr):
         - Create CaseFinding row: case_id, workflow_id, agent_type, agent_execution_id=execution_id, file_group_label, category=finding.category, title=finding.title, finding_text=finding.description (use finding.description since findings_text may not be populated yet -- but if output has findings_text field and it's not None, append it to the description for richer searchable text), confidence=finding.confidence, citations=[c.model_dump(mode="json") for c in finding.citations] (JSONB), entity_ids=[] (populated later via update_finding_entity_ids after KG entity extraction).
         - db.add() the finding.
       - await db.flush().
       - Return created findings.

    2. `async def update_finding_entity_ids(finding_id: UUID, entity_ids: list[str], db: AsyncSession) -> None` -- Update entity_ids JSONB after KG entities are created. This is called from the pipeline AFTER build_knowledge_graph completes, to backfill finding-to-entity links.

    3. `async def search_findings(db: AsyncSession, case_id: UUID, query: str, limit: int = 20) -> list[tuple[CaseFinding, float]]` -- Full-text search using tsvector.
       - Use SQLAlchemy's `func.plainto_tsquery('english', query)` and `func.ts_rank()`.
       - Query case_findings where case_id matches AND search_vector @@ tsquery.
       - Order by ts_rank descending, limit results.
       - Return list of (finding, relevance_score) tuples.
       - Use raw SQL text for the @@ operator since SQLAlchemy's support for tsvector operators is limited:
         ```python
         from sqlalchemy import text as sa_text, column, literal_column
         stmt = (
             select(
                 CaseFinding,
                 func.ts_rank(
                     literal_column("search_vector"),
                     func.plainto_tsquery("english", query),
                 ).label("rank"),
             )
             .where(
                 CaseFinding.case_id == case_id,
                 literal_column("search_vector").op("@@")(
                     func.plainto_tsquery("english", query)
                 ),
             )
             .order_by(literal_column("rank").desc())
             .limit(limit)
         )
         ```

    4. `async def list_findings(db: AsyncSession, case_id: UUID, agent_type: str | None = None, category: str | None = None, limit: int = 50, offset: int = 0) -> tuple[list[CaseFinding], int]` -- Paginated listing with optional filters.
       - Build query with optional where clauses for agent_type and category.
       - Return (findings_list, total_count).

    5. `async def get_finding_by_id(db: AsyncSession, finding_id: UUID, case_id: UUID) -> CaseFinding | None` -- Single finding lookup.
  </action>
  <verify>
    Run `cd backend && python -c "from app.services.findings_service import save_findings_from_output, search_findings, list_findings, update_finding_entity_ids; print('Findings service importable')"` to confirm no import errors.
  </verify>
  <done>Findings service with save, update_finding_entity_ids, search (tsvector), list, and get operations. All functions take db session as parameter. Vector search deferral documented.</done>
</task>

</tasks>

<verification>
1. KG Builder extracts entities from all 4 domain agent output types
2. Relationships are inferred from co-occurrence within findings
3. Deduplication: exact match auto-merges, fuzzy flags at 85%+
4. Merged entities use soft merge (merged_into_id, not deletion)
5. Degree computation counts connections correctly
6. Findings service saves all findings with citations
7. Full-text search returns ranked results
8. rapidfuzz dependency added to pyproject.toml
9. update_finding_entity_ids function exists for post-KG backfill
</verification>

<success_criteria>
- KG Builder processes domain_results dict and creates KgEntity + KgRelationship rows
- Entity deduplication merges exact matches, flags fuzzy matches
- Findings service persists findings with citations as JSONB
- Full-text search works on case_findings via tsvector
- No entities or relationships are lost/filtered during extraction
- update_finding_entity_ids available for pipeline to call after KG build
</success_criteria>

<output>
After completion, create `.planning/phases/07-knowledge-storage--and--domain-agent-enrichment/07-03-SUMMARY.md`
</output>
