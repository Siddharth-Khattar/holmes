---
phase: 07-knowledge-storage-and-domain-agent-enrichment
plan: 05
type: execute
wave: 3
depends_on: ["07-01", "07-02", "07-03"]
files_modified:
  - backend/app/api/knowledge_graph.py
  - backend/app/api/findings.py
  - backend/app/services/agent_events.py
  - backend/app/services/pipeline.py
  - backend/app/main.py
autonomous: true

must_haves:
  truths:
    - "GET /api/cases/:caseId/graph returns entities and relationships for frontend consumption"
    - "CRUD endpoints exist for entities and relationships (GET list, POST create, PATCH update, DELETE)"
    - "GET /api/cases/:caseId/findings returns paginated findings with optional agent_type filter"
    - "GET /api/cases/:caseId/findings/search returns full-text search results ranked by relevance"
    - "SSE events fire when findings are committed and KG entities are added during pipeline"
    - "Pipeline wiring calls KG Builder and findings service after domain agents complete"
    - "New routers registered in main.py"
  artifacts:
    - path: "backend/app/api/knowledge_graph.py"
      provides: "KG API endpoints: graph, entities CRUD, relationships CRUD"
      exports: ["router"]
    - path: "backend/app/api/findings.py"
      provides: "Findings API endpoints: list, detail, search"
      exports: ["router"]
    - path: "backend/app/services/agent_events.py"
      provides: "New SSE event types: FINDING_COMMITTED, KG_ENTITY_ADDED, KG_RELATIONSHIP_ADDED"
      contains: "FINDING_COMMITTED"
    - path: "backend/app/services/pipeline.py"
      provides: "Updated pipeline with KG Builder and findings storage stages"
      contains: "build_knowledge_graph"
    - path: "backend/app/main.py"
      provides: "New routers registered"
      contains: "knowledge_graph"
  key_links:
    - from: "backend/app/api/knowledge_graph.py"
      to: "backend/app/models/knowledge_graph.py"
      via: "SQLAlchemy queries for entity/relationship CRUD"
      pattern: "select\\(KgEntity\\)"
    - from: "backend/app/api/findings.py"
      to: "backend/app/services/findings_service.py"
      via: "Service layer for search and listing"
      pattern: "search_findings"
    - from: "backend/app/services/pipeline.py"
      to: "backend/app/services/kg_builder.py"
      via: "Pipeline calls KG Builder after domain agents"
      pattern: "build_knowledge_graph"
    - from: "backend/app/services/pipeline.py"
      to: "backend/app/services/findings_service.py"
      via: "Pipeline saves findings after domain agents"
      pattern: "save_findings_from_output"
    - from: "backend/app/main.py"
      to: "backend/app/api/knowledge_graph.py"
      via: "Router registration"
      pattern: "app.include_router\\(knowledge_graph.router"
---

<objective>
Create API endpoints for KG and findings, add SSE events, and wire KG Builder + findings storage into the pipeline.

Purpose: This plan connects all the pieces: the frontend can now query the KG and findings APIs, the pipeline automatically populates data after domain agents complete, and SSE events notify the frontend in real-time as knowledge is built.

Output: 2 new API routers, updated SSE events, updated pipeline, updated main.py.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-knowledge-storage--and--domain-agent-enrichment/07-RESEARCH.md
@.planning/phases/07-knowledge-storage--and--domain-agent-enrichment/07-CONTEXT.md
@backend/app/api/files.py
@backend/app/services/pipeline.py
@backend/app/services/agent_events.py
@backend/app/main.py
@backend/app/api/auth.py
@backend/app/database.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create KG and findings API routers</name>
  <files>
    backend/app/api/knowledge_graph.py
    backend/app/api/findings.py
    backend/app/main.py
  </files>
  <action>
    Follow the EXACT router pattern from `files.py` -- APIRouter with prefix, CurrentUser dependency, Depends(get_db), case ownership verification.

    **backend/app/api/knowledge_graph.py** (2-line ABOUTME):

    Router prefix: `/api/cases/{case_id}` (entity and relationship routes share the case context).

    Endpoints:

    1. `GET /api/cases/{case_id}/graph` -> GraphResponse
       - Query all KgEntity rows for case_id WHERE merged_into_id IS NULL (exclude merged duplicates).
       - Query all KgRelationship rows for case_id.
       - Return GraphResponse with entities, relationships, counts.
       - Verify case ownership (query Case where id=case_id and user_id matches current_user.id).

    2. `GET /api/cases/{case_id}/entities` -> EntityListResponse
       - Optional query params: entity_type (str), domain (str), search (str for name search), limit (int=50), offset (int=0).
       - Filter by entity_type and domain if provided.
       - If search provided, filter where name ILIKE %search%.
       - WHERE merged_into_id IS NULL.
       - Return EntityListResponse with total count.

    3. `POST /api/cases/{case_id}/entities` -> EntityResponse (status 201)
       - Accept EntityCreateRequest body.
       - Create KgEntity with case_id, name_normalized computed from name.
       - Return created entity.

    4. `PATCH /api/cases/{case_id}/entities/{entity_id}` -> EntityResponse
       - Accept EntityUpdateRequest body.
       - Query entity by id AND case_id (prevent cross-case access).
       - Update only provided (non-None) fields. If name changes, recompute name_normalized.
       - Return updated entity.

    5. `DELETE /api/cases/{case_id}/entities/{entity_id}` -> 204 No Content
       - Query entity by id AND case_id.
       - Hard delete the entity (cascade deletes relationships).
       - Return 204.

    6. `GET /api/cases/{case_id}/relationships` -> RelationshipListResponse
       - Optional query params: entity_id (UUID, filter relationships involving this entity), relationship_type (str), limit (int=50), offset (int=0).
       - If entity_id provided, filter where source_entity_id OR target_entity_id matches.
       - Return with total count.

    7. `POST /api/cases/{case_id}/relationships` -> RelationshipResponse (status 201)
       - Accept RelationshipCreateRequest body.
       - Verify both source and target entities belong to the case.
       - Create KgRelationship with case_id.
       - Return created relationship.

    **Helper function (private):** `_get_user_case(db, case_id, user_id)` -- reuse the pattern from other API files. Query Case where id=case_id and user_id matches. Return Case or raise 404.

    **backend/app/api/findings.py** (2-line ABOUTME):

    Router prefix: `/api/cases/{case_id}/findings`

    Endpoints:

    1. `GET /api/cases/{case_id}/findings` -> FindingListResponse
       - Query params: agent_type (str, optional), category (str, optional), limit (int=50, default), offset (int=0).
       - Call `findings_service.list_findings()`.
       - Verify case ownership.

    2. `GET /api/cases/{case_id}/findings/{finding_id}` -> FindingResponse
       - Call `findings_service.get_finding_by_id()`.
       - Verify case_id matches.
       - Return 404 if not found.

    3. `GET /api/cases/{case_id}/findings/search` -> FindingSearchResponse
       - Query params: q (str, required), limit (int=20).
       - Call `findings_service.search_findings()`.
       - Return FindingSearchResponse with results and relevance scores.

    IMPORTANT: The `/search` endpoint must be defined BEFORE `/{finding_id}` in the router to avoid the path parameter catching "search" as a finding_id. Alternatively, use a POST endpoint for search or add type validation on finding_id (UUID).

    **backend/app/main.py**: Add two new router registrations:
    ```python
    from app.api import knowledge_graph, findings
    app.include_router(knowledge_graph.router, tags=["knowledge-graph"])
    app.include_router(findings.router, tags=["findings"])
    ```
    Place these after the existing `agents` and `confirmations` router includes.
  </action>
  <verify>
    Run `cd backend && python -c "from app.api.knowledge_graph import router as kg_router; from app.api.findings import router as findings_router; print(f'KG routes: {len(kg_router.routes)}, Findings routes: {len(findings_router.routes)}')"` to confirm routers are importable and have routes.

    Run `cd backend && python -c "from app.main import app; routes = [r.path for r in app.routes]; assert any('graph' in r for r in routes); assert any('findings' in r for r in routes); print('Routers registered in app')"` to confirm registration.
  </verify>
  <done>KG API with 7 endpoints (graph, entities CRUD, relationships CRUD). Findings API with 3 endpoints (list, detail, search). Both registered in main.py.</done>
</task>

<task type="auto">
  <name>Task 2: Add SSE events and wire KG Builder + findings into pipeline</name>
  <files>
    backend/app/services/agent_events.py
    backend/app/services/pipeline.py
  </files>
  <action>
    **backend/app/services/agent_events.py changes:**

    1. Add 3 new event types to `AgentEventType` enum:
       ```python
       FINDING_COMMITTED = "finding-committed"
       KG_ENTITY_ADDED = "kg-entity-added"
       KG_RELATIONSHIP_ADDED = "kg-relationship-added"
       ```

    2. Add 3 convenience emitter functions following the existing pattern (e.g., `emit_agent_started`):

       ```python
       async def emit_finding_committed(
           case_id: str,
           finding_id: str,
           agent_type: str,
           title: str,
       ) -> None:
           await publish_agent_event(
               case_id,
               AgentEventType.FINDING_COMMITTED,
               {
                   "type": AgentEventType.FINDING_COMMITTED.value,
                   "findingId": finding_id,
                   "agentType": agent_type,
                   "title": title,
               },
           )

       async def emit_kg_entity_added(
           case_id: str,
           entity_id: str,
           entity_name: str,
           entity_type: str,
       ) -> None:
           await publish_agent_event(
               case_id,
               AgentEventType.KG_ENTITY_ADDED,
               {
                   "type": AgentEventType.KG_ENTITY_ADDED.value,
                   "entityId": entity_id,
                   "entityName": entity_name,
                   "entityType": entity_type,
               },
           )

       async def emit_kg_relationship_added(
           case_id: str,
           relationship_id: str,
           source_entity_name: str,
           target_entity_name: str,
           relationship_type: str,
       ) -> None:
           await publish_agent_event(
               case_id,
               AgentEventType.KG_RELATIONSHIP_ADDED,
               {
                   "type": AgentEventType.KG_RELATIONSHIP_ADDED.value,
                   "relationshipId": relationship_id,
                   "sourceEntityName": source_entity_name,
                   "targetEntityName": target_entity_name,
                   "relationshipType": relationship_type,
               },
           )
       ```

    **backend/app/services/pipeline.py changes:**

    Insert KG Builder and findings storage AFTER the HITL stage (after line ~918, the last HITL confirmation block) and BEFORE the "Final: Update file statuses to ANALYZED" section (currently around line ~920).

    Add lazy imports at the top of `run_analysis_workflow` (inside the function body, alongside existing lazy imports):
    ```python
    from app.services.kg_builder import build_knowledge_graph
    from app.services.findings_service import save_findings_from_output
    from app.services.agent_events import (
        emit_finding_committed,
        emit_kg_entity_added,
        emit_kg_relationship_added,
    )
    ```
    Note: emit_finding_committed etc. should be added to the existing agent_events import at the top of the file OR added as lazy imports. Since agent_events is already imported at module level, add the new emitters to the existing import statement at the top of the file.

    Add the following new stages BETWEEN the HITL block and the "Final: Update file statuses" block:

    ```python
    # ---- Stage 6: Save Findings to case_findings ----
    logger.info(
        "Pipeline starting stage=save_findings case=%s workflow=%s",
        case_id, workflow_id,
    )
    all_saved_findings = []
    for domain_agent, domain_run_list in domain_results.items():
        for domain_output, grp_label in domain_run_list:
            if domain_output is None:
                continue
            # Query execution record for this agent+group
            exec_result = await db.execute(
                select(AgentExecution)
                .where(
                    AgentExecution.workflow_id == UUID(workflow_id),
                    AgentExecution.agent_name == domain_agent,
                )
                .order_by(AgentExecution.created_at.desc())
                .limit(1)
            )
            agent_exec = exec_result.scalar_one_or_none()
            execution_id = agent_exec.id if agent_exec else None

            output_data = domain_output.model_dump(mode="json") if hasattr(domain_output, "model_dump") else {}
            saved = await save_findings_from_output(
                output_data=output_data,
                agent_type=domain_agent,
                execution_id=execution_id,
                case_id=UUID(case_id),
                workflow_id=UUID(workflow_id),
                file_group_label=grp_label,
                db=db,
            )
            all_saved_findings.extend(saved)
            for f in saved:
                await emit_finding_committed(
                    case_id=case_id,
                    finding_id=str(f.id),
                    agent_type=domain_agent,
                    title=f.title,
                )

    # Also save strategy findings if available
    if strategy_result:
        strat_exec_result2 = await db.execute(
            select(AgentExecution)
            .where(
                AgentExecution.workflow_id == UUID(workflow_id),
                AgentExecution.agent_name == "strategy",
            )
            .order_by(AgentExecution.created_at.desc())
            .limit(1)
        )
        strat_exec2 = strat_exec_result2.scalar_one_or_none()
        strat_output_data = strategy_result.model_dump(mode="json") if hasattr(strategy_result, "model_dump") else {}
        strat_saved = await save_findings_from_output(
            output_data=strat_output_data,
            agent_type="strategy",
            execution_id=strat_exec2.id if strat_exec2 else None,
            case_id=UUID(case_id),
            workflow_id=UUID(workflow_id),
            file_group_label="strategy",
            db=db,
        )
        all_saved_findings.extend(strat_saved)
        for f in strat_saved:
            await emit_finding_committed(
                case_id=case_id,
                finding_id=str(f.id),
                agent_type="strategy",
                title=f.title,
            )

    await db.commit()  # Commit findings before KG building

    # ---- Stage 7: Build Knowledge Graph ----
    logger.info(
        "Pipeline starting stage=kg_builder case=%s workflow=%s",
        case_id, workflow_id,
    )
    entities_created, relationships_created, exact_merges = await build_knowledge_graph(
        case_id=case_id,
        workflow_id=workflow_id,
        domain_results=domain_results,
        strategy_result=strategy_result,
        db=db,
    )
    await db.commit()  # Commit KG data

    logger.info(
        "KG build complete case=%s entities=%d relationships=%d merges=%d",
        case_id, entities_created, relationships_created, exact_merges,
    )
    ```

    NOTE: The `build_knowledge_graph` function signature may need adjustment -- it should also accept `strategy_result` or iterate over domain_results which should include strategy. The cleanest approach: before calling build_knowledge_graph, add strategy_result to domain_results if it exists:
    ```python
    if strategy_result:
        domain_results.setdefault("strategy", []).append((strategy_result, "strategy"))
    ```
    This way the KG Builder processes strategy entities too.

    Update the `emit_processing_complete` call to include actual entity and relationship counts:
    ```python
    entities_created=total_entities + total_domain_entities + entities_created,  # Include KG entities
    relationships_created=relationships_created,  # Now populated
    ```

    Also, for SSE emission of individual entities (optional but nice for real-time UX), the KG Builder should accept an optional callback or the pipeline should emit after build_knowledge_graph returns. Since emitting per-entity could be noisy for large graphs, emit a SUMMARY event instead by reusing the existing pattern. Actually, skip per-entity SSE for now -- the processing-complete event already signals the frontend to refresh, and the KG API provides the data. We added the emitters in agent_events.py for future use but don't need to call them per-entity in the pipeline yet (would be too noisy).
  </action>
  <verify>
    Run `cd backend && python -c "from app.services.agent_events import AgentEventType; assert hasattr(AgentEventType, 'FINDING_COMMITTED'); assert hasattr(AgentEventType, 'KG_ENTITY_ADDED'); print('New SSE event types registered')"` to confirm new event types.

    Run `cd backend && python -c "from app.services.agent_events import emit_finding_committed, emit_kg_entity_added, emit_kg_relationship_added; print('New SSE emitters importable')"` to confirm emitters.

    Run the type check and format commands: `cd /Users/siddharth/Development/Hackathons/Gemini_3_2025/holmes && make generate-types && make format` (or the equivalent commands from Makefile).

    Run `cd backend && python -c "from app.services.pipeline import run_analysis_workflow; print('Pipeline importable')"` to confirm no circular import or syntax errors.
  </verify>
  <done>3 new SSE event types + emitters. Pipeline updated with findings storage + KG Builder stages. New API routers registered. Full pipeline flow: Triage -> Orchestrator -> Domain -> Strategy -> HITL -> Save Findings -> Build KG -> Final.</done>
</task>

</tasks>

<verification>
1. KG API endpoints return valid responses (verify route paths exist)
2. Findings API endpoints return valid responses with search support
3. SSE event types FINDING_COMMITTED, KG_ENTITY_ADDED, KG_RELATIONSHIP_ADDED exist
4. Pipeline calls save_findings_from_output for each domain agent result
5. Pipeline calls build_knowledge_graph after findings are saved
6. processing-complete event includes real entity/relationship counts
7. New routers registered in main.py
8. Type check passes, format applied
</verification>

<success_criteria>
- 7 KG API endpoints (graph, entities CRUD, relationships CRUD) operational
- 3 findings API endpoints (list, detail, search) operational
- 3 new SSE event types registered
- Pipeline wiring: findings saved, KG built, events emitted after domain agents
- Full pipeline: Triage -> Orchestrator -> Domain -> Strategy -> HITL -> Findings -> KG -> Final
- `make generate-types && make format` succeeds
</success_criteria>

<output>
After completion, create `.planning/phases/07-knowledge-storage--and--domain-agent-enrichment/07-05-SUMMARY.md`
</output>
