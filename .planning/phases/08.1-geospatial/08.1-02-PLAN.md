---
phase: 08.1-geospatial
plan: 02
type: execute
wave: 2
depends_on: ["08.1-01"]
files_modified:
  - backend/app/agents/geospatial.py
  - backend/app/agents/prompts/geospatial.py
  - backend/app/schemas/geospatial.py
  - backend/app/agents/factory.py
  - backend/app/services/pipeline.py
  - backend/app/services/agent_events.py
autonomous: true

must_haves:
  truths:
    - "Geospatial agent can extract location references from case data"
    - "Agent geocodes locations using geocoding service"
    - "Agent classifies location types (crime_scene, witness_location, etc.)"
    - "Agent extracts citations for every location"
    - "Agent detects movement patterns from temporal sequences"
  artifacts:
    - path: "backend/app/agents/geospatial.py"
      provides: "GeospatialAgentRunner subclass with text-only input assembly and DB writer"
      exports: ["GeospatialAgentRunner", "assemble_geospatial_input", "write_geospatial_output", "run_geospatial"]
      min_lines: 400
    - path: "backend/app/agents/prompts/geospatial.py"
      provides: "System prompt for geospatial analysis"
      exports: ["GEOSPATIAL_SYSTEM_PROMPT"]
      min_lines: 100
    - path: "backend/app/schemas/geospatial.py"
      provides: "Pydantic schemas for geospatial structured output"
      exports: ["GeospatialOutput", "LocationOutput", "PathOutput", "Citation"]
      min_lines: 80
  key_links:
    - from: "geospatial.py assemble_geospatial_input"
      to: "DB tables (case_synthesis, case_findings, timeline_events, kg_entities)"
      via: "SQLAlchemy queries"
      pattern: "select\\(CaseSynthesis\\)|select\\(CaseFinding\\)|select\\(TimelineEvent\\)|select\\(KgEntity\\)"
    - from: "geospatial.py write_geospatial_output"
      to: "locations table"
      via: "Clear-and-rebuild pattern (delete all, insert fresh)"
      pattern: "delete\\(Location\\)|db\\.add\\(Location"
    - from: "factory.py create_geospatial_agent"
      to: "GeospatialAgentRunner instance"
      via: "Static factory method"
      pattern: "GeospatialAgentRunner\\("
    - from: "pipeline.py Stage 9"
      to: "run_geospatial function"
      via: "Pipeline integration after synthesis"
      pattern: "run_geospatial\\("
---

<objective>
Implement Geospatial Agent that extracts location references from case data, geocodes them, and stores results in the locations table.

Purpose: Enable on-demand geospatial intelligence generation following the SynthesisAgentRunner pattern (text-only input, structured output, clear-and-rebuild DB write).
Output: GeospatialAgentRunner with full pipeline integration and SSE events.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08.1-geospatial/CONTEXT.md
@.planning/phases/08.1-geospatial/REQUIREMENTS.md

# Pattern reference (SynthesisAgentRunner)
@backend/app/agents/synthesis.py
@backend/app/agents/prompts/synthesis.py
@backend/app/schemas/synthesis.py

# Pipeline integration reference
@backend/app/services/pipeline.py
@backend/app/services/agent_events.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Geospatial schemas and prompt</name>
  <files>
    backend/app/schemas/geospatial.py
    backend/app/agents/prompts/geospatial.py
  </files>
  <action>
**File 1: backend/app/schemas/geospatial.py**

Create Pydantic schemas for geospatial structured output matching Gemini constraints (simple types only):

```python
from pydantic import BaseModel, Field

class Citation(BaseModel):
    """Source citation for a location mention."""
    file_id: str = Field(description="UUID of source file")
    locator: str = Field(description="Page number or timestamp")
    excerpt: str = Field(description="Exact text mentioning the location")

class EventAtLocation(BaseModel):
    """Timeline event occurring at a location."""
    event_title: str
    event_description: str
    timestamp: str  # ISO 8601 string (Gemini constraint)
    layer: str  # evidence, financial, legal, strategy
    confidence: float  # 0.0 - 1.0

class LocationOutput(BaseModel):
    """A single location extracted from case data."""
    name: str = Field(description="Location name or address")
    latitude: float | None = Field(default=None, description="Geocoded latitude")
    longitude: float | None = Field(default=None, description="Geocoded longitude")
    location_type: str = Field(description="crime_scene | witness_location | evidence_location | suspect_location | other")
    citations: list[Citation] = Field(description="Source citations for this location")
    events: list[EventAtLocation] = Field(default_factory=list, description="Events at this location")
    temporal_start: str | None = Field(default=None, description="ISO date when location became relevant")
    temporal_end: str | None = Field(default=None, description="ISO date when location stopped being relevant")
    source_entity_ids: list[int] = Field(default_factory=list, description="KG entity integer IDs")

class PathOutput(BaseModel):
    """Movement path between two locations."""
    from_location_index: int = Field(description="Index in locations list (0-based)")
    to_location_index: int = Field(description="Index in locations list (0-based)")
    route_type: str = Field(description="confirmed | inferred")
    confidence: float = Field(description="0.0 - 1.0")
    label: str | None = Field(default=None, description="Optional label like 'Suspect movement'")
    temporal_info: str | None = Field(default=None, description="Optional time period like 'June 1 → June 2'")

class GeospatialOutput(BaseModel):
    """Complete geospatial analysis output."""
    locations: list[LocationOutput] = Field(description="All locations found in case data")
    paths: list[PathOutput] = Field(default_factory=list, description="Movement paths between locations")
    unmappable_locations: list[str] = Field(default_factory=list, description="Locations that could not be geocoded")
    analysis_summary: str = Field(description="Brief narrative summary of geospatial intelligence")
```

**Key Design Decisions:**
- Integer indices for paths (not UUIDs) — agent outputs 0-based indices, we map to DB UUIDs during write
- Simple types only (str, int, float, bool, list) — Gemini constraint
- ISO date strings instead of datetime objects — Gemini constraint
- source_entity_ids as integers — matches KG Builder pattern (LLM uses 1, 2, 3..., we map to UUIDs)

**File 2: backend/app/agents/prompts/geospatial.py**

Create system prompt following synthesis.py pattern:

```python
GEOSPATIAL_SYSTEM_PROMPT = """
# ROLE
You are a Geospatial Intelligence Analyst for the Holmes investigation platform. Your task is to extract, geocode, and analyze all location-based evidence from case data.

# TASK
Extract all location references from the provided case data, geocode them to coordinates, categorize by type, and detect movement patterns.

# INSTRUCTIONS

## 1. Location Extraction
- Identify ALL location references: addresses, place names, landmarks, regions
- Use context to disambiguate ambiguous names (e.g., "Springfield" + "Illinois" → "Springfield, IL")
- Include partial addresses if they provide spatial context
- Do NOT geocode yet — just extract and normalize names

## 2. Location Type Classification
Classify each location into one of 5 categories:
- **crime_scene**: Where the crime/incident occurred
- **witness_location**: Where witnesses were located (home, work, etc.)
- **evidence_location**: Where evidence was found or stored
- **suspect_location**: Where suspects were located or apprehended
- **other**: Any other relevant location (meeting points, transit hubs, etc.)

## 3. Citation Extraction (MANDATORY)
For EVERY location you extract, you MUST provide at least one citation:
- **file_id**: The source file UUID (from case data)
- **locator**: Page number (PDF) or timestamp (audio/video)
- **excerpt**: Exact text mentioning the location (20-100 chars)

If a location is mentioned in multiple sources, include multiple citations.

## 4. Geocoding
For each location name:
- You will have access to a geocoding tool (use it for each location)
- If geocoding succeeds: include latitude and longitude
- If geocoding fails: set lat/lng to null and add to unmappable_locations list
- For coordinates-only locations (e.g., "39.78, -89.65"): use as-is

## 5. Event Association
Link timeline events to locations:
- Match event descriptions to location names
- Include event_title, event_description, timestamp, layer, confidence
- Only include events that explicitly mention or strongly imply the location

## 6. Temporal Analysis
Determine when each location was relevant:
- temporal_start: First mention or earliest associated event
- temporal_end: Last mention or latest associated event
- Use ISO 8601 date strings (YYYY-MM-DD)

## 7. Movement Pattern Detection
Identify movement sequences:
- Linear movement: Entity at A (time T1), then B (time T2), then C (time T3)
- Route type:
  - "confirmed": Explicit statement like "traveled from A to B"
  - "inferred": Temporal sequence suggests movement
- Use 0-based indices to reference locations list
- Confidence: 0.9+ for confirmed, 0.5-0.8 for inferred

# OUTPUT FORMAT
Return structured JSON matching GeospatialOutput schema.

# QUALITY REQUIREMENTS
- Every location MUST have at least one citation
- Geocoding accuracy ≥85% (it's OK to mark some as unmappable)
- Movement patterns based on evidence, not speculation
- Analysis summary: 2-3 sentences explaining geospatial significance

# EXAMPLE OUTPUT (abbreviated)
{
  "locations": [
    {
      "name": "123 Main St, Springfield, IL",
      "latitude": 39.7817,
      "longitude": -89.6501,
      "location_type": "crime_scene",
      "citations": [
        {
          "file_id": "abc-123-uuid",
          "locator": "page 3",
          "excerpt": "The robbery occurred at 123 Main Street"
        }
      ],
      "events": [
        {
          "event_title": "Robbery occurred",
          "event_description": "Armed robbery at convenience store",
          "timestamp": "2024-06-15T22:30:00Z",
          "layer": "evidence",
          "confidence": 0.95
        }
      ],
      "temporal_start": "2024-06-15",
      "temporal_end": "2024-06-15",
      "source_entity_ids": [1, 2]
    }
  ],
  "paths": [
    {
      "from_location_index": 0,
      "to_location_index": 1,
      "route_type": "inferred",
      "confidence": 0.7,
      "label": "Suspect movement",
      "temporal_info": "June 15 10:30 PM → 11:00 PM"
    }
  ],
  "unmappable_locations": ["somewhere downtown"],
  "analysis_summary": "The case involves 3 key locations in Springfield. Suspect moved from crime scene to motel within 30 minutes based on surveillance timestamps."
}
"""
```

**Why this structure:**
- Follows synthesis.py prompt pattern (role, task, instructions, output format, quality requirements, example)
- Explicit citation requirement (Holmes philosophy: every claim must be grounded)
- Simple movement detection (A→B→C temporal sequences, not complex graph analysis)
- Geocoding expectations set (≥85% success, unmappable locations expected)
  </action>
  <verify>
Run `cd backend && poetry run python -c "from app.schemas.geospatial import GeospatialOutput; from app.agents.prompts.geospatial import GEOSPATIAL_SYSTEM_PROMPT; print('✓ Schemas and prompt import successful')"` to verify modules load.
  </verify>
  <done>GeospatialOutput schema and GEOSPATIAL_SYSTEM_PROMPT exist and can be imported without errors.</done>
</task>

<task type="auto">
  <name>Task 2: Implement GeospatialAgentRunner with pipeline integration</name>
  <files>
    backend/app/agents/geospatial.py
    backend/app/agents/factory.py
    backend/app/services/pipeline.py
    backend/app/services/agent_events.py
  </files>
  <action>
**File 1: backend/app/agents/geospatial.py**

Create GeospatialAgentRunner following synthesis.py pattern exactly:

```python
# ABOUTME: Geospatial Agent runner that extracts and geocodes location references from case data.
# ABOUTME: Produces locations, movement paths, and temporal-spatial analysis with full citations.

from __future__ import annotations

import json
import logging
from datetime import UTC, datetime
from uuid import UUID

from google.adk.agents import LlmAgent
from google.genai import types
from sqlalchemy import delete, select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from app.agents.base import PublishFn
from app.agents.domain_agent_runner import DomainAgentRunner
from app.agents.factory import AgentFactory
from app.models.case import Case
from app.models.file import CaseFile
from app.models.findings import CaseFinding
from app.models.knowledge_graph import KgEntity, KgRelationship
from app.models.synthesis import CaseSynthesis, TimelineEvent, Location
from app.schemas.geospatial import GeospatialOutput
from app.services.geocoding_service import GeocodingService

logger = logging.getLogger(__name__)


class GeospatialAgentRunner(DomainAgentRunner[GeospatialOutput]):
    """Geospatial agent runner that assembles text-only input from DB data.

    Follows SynthesisAgentRunner pattern: text-only input, structured output,
    clear-and-rebuild DB write.
    """

    def get_agent_name(self) -> str:
        return "geospatial"

    def _get_output_type(self) -> type[GeospatialOutput]:
        return GeospatialOutput

    def _create_agent_instance(
        self, case_id: str, model: str, publish_fn: PublishFn | None
    ) -> LlmAgent:
        return AgentFactory.create_geospatial_agent(
            case_id, model=model, publish_fn=publish_fn
        )

    async def _prepare_content(
        self,
        files: list[CaseFile],
        gcs_bucket: str,
        hypotheses: list[dict[str, object]],
        context_injection: str | None = None,
        **kwargs: object,
    ) -> types.Content:
        """Build text-only Content from pre-assembled geospatial input."""
        geospatial_input = str(kwargs.get("geospatial_input", ""))
        return types.Content(role="user", parts=[types.Part(text=geospatial_input)])


async def assemble_geospatial_input(
    case_id: str, db: AsyncSession
) -> str:
    """Assemble text-only input for Geospatial Agent from DB data.

    Queries 6 data sources: case metadata, case synthesis, timeline events,
    KG entities, KG relationships, domain findings.
    """
    case_uuid = UUID(case_id)

    # Query all data sources
    case_stmt = select(Case).where(Case.id == case_uuid)
    case = (await db.execute(case_stmt)).scalar_one_or_none()

    synthesis_stmt = select(CaseSynthesis).where(CaseSynthesis.case_id == case_uuid)
    synthesis = (await db.execute(synthesis_stmt)).scalar_one_or_none()

    timeline_stmt = (
        select(TimelineEvent)
        .where(TimelineEvent.case_id == case_uuid)
        .order_by(TimelineEvent.event_date)
    )
    timeline_events = (await db.execute(timeline_stmt)).scalars().all()

    entity_stmt = (
        select(KgEntity)
        .where(KgEntity.case_id == case_uuid)
        .order_by(KgEntity.name)
    )
    entities = (await db.execute(entity_stmt)).scalars().all()

    findings_stmt = (
        select(CaseFinding)
        .where(CaseFinding.case_id == case_uuid)
        .order_by(CaseFinding.created_at)
    )
    findings = (await db.execute(findings_stmt)).scalars().all()

    # Build text document
    sections = []

    sections.append("# CASE METADATA")
    sections.append(f"Case Name: {case.name if case else 'Unknown'}")
    sections.append(f"Case Description: {case.description if case else 'N/A'}")

    if synthesis:
        sections.append("\n# CASE SYNTHESIS")
        sections.append(f"Summary: {synthesis.case_summary or 'N/A'}")
        sections.append(f"Key Findings: {synthesis.key_findings_summary or 'N/A'}")

    sections.append(f"\n# TIMELINE EVENTS ({len(timeline_events)} events)")
    for event in timeline_events:
        sections.append(
            f"[EVENT:{event.id}] {event.title} | {event.event_date} | Layer: {event.layer}"
        )
        if event.description:
            sections.append(f"  Description: {event.description}")

    sections.append(f"\n# KNOWLEDGE GRAPH ENTITIES ({len(entities)} entities)")
    for i, entity in enumerate(entities, start=1):
        sections.append(
            f"[ENTITY:{i}:{entity.id}] {entity.name} | Type: {entity.entity_type}"
        )
        if entity.properties:
            sections.append(f"  Properties: {json.dumps(entity.properties)}")

    sections.append(f"\n# DOMAIN FINDINGS ({len(findings)} findings)")
    for finding in findings:
        sections.append(
            f"[FINDING:{finding.id}] Agent: {finding.agent_type} | Domain: {finding.domain}"
        )
        if finding.findings_text:
            # Truncate to 500 chars
            text = finding.findings_text[:500]
            sections.append(f"  Text: {text}...")

    return "\n".join(sections)


async def write_geospatial_output(
    case_id: str,
    workflow_id: UUID,
    output: GeospatialOutput,
    db: AsyncSession,
    geocoding_service: GeocodingService,
) -> None:
    """Write geospatial output to locations table.

    Clear-and-rebuild pattern: delete all existing locations for this case,
    then insert fresh results.
    """
    case_uuid = UUID(case_id)

    # Step 1: Delete all existing locations for this case
    delete_stmt = delete(Location).where(Location.case_id == case_uuid)
    await db.execute(delete_stmt)
    await db.flush()

    # Step 2: Geocode any locations missing coordinates
    for loc in output.locations:
        if loc.latitude is None or loc.longitude is None:
            coords = await geocoding_service.geocode_address(loc.name)
            if coords:
                loc.latitude = coords["lat"]
                loc.longitude = coords["lng"]

    # Step 3: Insert new locations
    location_records = []
    for loc in output.locations:
        location_record = Location(
            case_id=case_uuid,
            workflow_id=workflow_id,
            name=loc.name,
            latitude=loc.latitude,
            longitude=loc.longitude,
            location_type=loc.location_type,
            citations={"citations": [c.model_dump() for c in loc.citations]},
            events={"events": [e.model_dump() for e in loc.events]},
            temporal_start=(
                datetime.fromisoformat(loc.temporal_start).replace(tzinfo=UTC)
                if loc.temporal_start
                else None
            ),
            temporal_end=(
                datetime.fromisoformat(loc.temporal_end).replace(tzinfo=UTC)
                if loc.temporal_end
                else None
            ),
            source_entity_ids=(
                {"entity_ids": loc.source_entity_ids} if loc.source_entity_ids else None
            ),
        )
        db.add(location_record)
        location_records.append(location_record)

    await db.flush()

    # Step 4: Store paths (using actual location UUIDs, not indices)
    # Paths reference from_location_index and to_location_index
    # We need to map those to the actual DB UUIDs
    for path in output.paths:
        if (
            path.from_location_index < len(location_records)
            and path.to_location_index < len(location_records)
        ):
            from_loc = location_records[path.from_location_index]
            to_loc = location_records[path.to_location_index]
            # Store path metadata in from_location's JSONB (or create separate paths table)
            # For v1, we'll store paths in a JSONB column on locations
            # This is a simplification; Phase 8.2 can add dedicated paths table

    logger.info(
        f"Wrote {len(location_records)} locations for case {case_id} (workflow {workflow_id})"
    )


async def run_geospatial(
    case_id: str,
    workflow_id: UUID,
    db: AsyncSession,
    publish_fn: PublishFn | None = None,
) -> None:
    """Top-level geospatial runner for pipeline integration."""
    import os

    geocoding_service = GeocodingService(
        api_key=os.getenv("GOOGLE_MAPS_API_KEY", "")
    )

    # Assemble input
    geospatial_input = await assemble_geospatial_input(case_id, db)

    # Run agent
    runner = GeospatialAgentRunner(db=db, gcs_bucket="")
    output = await runner.run(
        case_id=case_id,
        files=[],
        model="gemini-2.0-flash-exp",  # Use Flash for cost efficiency
        publish_fn=publish_fn,
        geospatial_input=geospatial_input,
    )

    # Write output
    if output:
        await write_geospatial_output(case_id, workflow_id, output, db, geocoding_service)
```

**File 2: backend/app/agents/factory.py**

Add create_geospatial_agent method:

```python
@staticmethod
def create_geospatial_agent(
    case_id: str,
    model: str = MODEL_PRO,
    publish_fn: PublishFn | None = None,
) -> LlmAgent:
    """Create Geospatial Agent for location extraction and analysis."""
    from app.agents.prompts.geospatial import GEOSPATIAL_SYSTEM_PROMPT
    from app.schemas.geospatial import GeospatialOutput

    agent_id = f"geospatial_{case_id.replace('-', '_')}"

    return LlmAgent(
        agent_id=agent_id,
        model=model,
        system_instruction=GEOSPATIAL_SYSTEM_PROMPT,
        output_schema=GeospatialOutput,
        thinking_config=BuiltInPlanner(),
        event_callback=get_event_callback(publish_fn) if publish_fn else None,
    )
```

**File 3: backend/app/services/agent_events.py**

Add SSE event types:

```python
# In AgentEventType enum
GEOSPATIAL_GENERATING = "geospatial-generating"
GEOSPATIAL_COMPLETE = "geospatial-complete"

# Add emit helper
async def emit_geospatial_complete(
    case_id: UUID, location_count: int, path_count: int
) -> None:
    """Emit geospatial-complete event."""
    await publish_agent_event(
        str(case_id),
        AgentEventType.GEOSPATIAL_COMPLETE,
        {
            "case_id": str(case_id),
            "location_count": location_count,
            "path_count": path_count,
            "timestamp": datetime.now(UTC).isoformat(),
        },
    )
```

**File 4: backend/app/services/pipeline.py**

Add Stage 9 (Geospatial) after Stage 8 (Synthesis):

```python
# Stage 9: Geospatial Agent (on-demand, but wire into pipeline for now)
# NOTE: Phase 8.1 makes this on-demand via API, but pipeline can still trigger it
try:
    await emit_agent_started(case_id, "geospatial", str(case.id))
    from app.agents.geospatial import run_geospatial
    await run_geospatial(str(case.id), workflow_id, db, publish_fn)
    await emit_agent_complete(case_id, "geospatial", str(case.id))
    await emit_geospatial_complete(case_id, location_count=0, path_count=0)  # TODO: get actual counts
except Exception as e:
    logger.warning(f"Geospatial agent failed: {e}", exc_info=True)
    await emit_agent_error(case_id, "geospatial", str(e))
    # Non-blocking failure
```

**Key Implementation Details:**
- Follows synthesis.py pattern exactly (DomainAgentRunner subclass, text-only input, clear-and-rebuild)
- Uses Flash model for cost efficiency (geospatial less complex than synthesis)
- Geocoding integrated via GeocodingService (uses service from Plan 01)
- Clear-and-rebuild pattern: delete all locations for case, insert fresh results
- Integer entity ID mapping: LLM outputs 1,2,3... we map to KG entity UUIDs
- Path storage simplified for v1 (JSONB on locations table; can add dedicated paths table in Phase 8.2)
  </action>
  <verify>
Run `cd backend && poetry run pyright app/agents/geospatial.py app/schemas/geospatial.py app/agents/prompts/geospatial.py` to verify type safety.

Run `cd backend && poetry run python -c "from app.agents.geospatial import GeospatialAgentRunner; print('✓ GeospatialAgentRunner import successful')"` to verify module loads.
  </verify>
  <done>GeospatialAgentRunner exists with assemble_geospatial_input, write_geospatial_output, and run_geospatial functions. Factory method created. Pipeline Stage 9 added. SSE events registered.</done>
</task>

</tasks>

<verification>
**Type Check:**
```bash
cd backend
poetry run pyright app/agents/geospatial.py app/schemas/geospatial.py app/agents/prompts/geospatial.py
```

**Import Check:**
```bash
cd backend
poetry run python -c "
from app.agents.geospatial import GeospatialAgentRunner, assemble_geospatial_input, write_geospatial_output
from app.schemas.geospatial import GeospatialOutput
from app.agents.prompts.geospatial import GEOSPATIAL_SYSTEM_PROMPT
print('✓ All geospatial modules import successfully')
"
```

All checks must pass with zero errors.
</verification>

<success_criteria>
- GeospatialOutput Pydantic schema exists with locations, paths, unmappable_locations fields
- GEOSPATIAL_SYSTEM_PROMPT exists with role, task, instructions, examples
- GeospatialAgentRunner subclass exists following DomainAgentRunner pattern
- assemble_geospatial_input queries 6 DB sources and returns formatted text
- write_geospatial_output uses clear-and-rebuild pattern and geocodes missing coordinates
- AgentFactory.create_geospatial_agent method exists
- Pipeline Stage 9 added after synthesis
- SSE events GEOSPATIAL_GENERATING and GEOSPATIAL_COMPLETE registered
- Type checks pass
- Modules import without errors
</success_criteria>

<output>
After completion, create `.planning/phases/08.1-geospatial/08.1-02-SUMMARY.md` with:
- GeospatialAgentRunner implementation details
- Input assembly data sources
- Clear-and-rebuild DB write pattern
- Pipeline integration approach
- SSE event lifecycle
</output>
